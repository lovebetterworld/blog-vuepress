---
title: 万字详解数仓分层设计架构 ODS-DWD-DWS-ADS
date: 2022-10-26 09:47:50
permalink: /bigdata/datahub04/
categories:
  - 数据仓库
tags:
  - 数据仓库
---

- [万字详解数仓分层设计架构 ODS-DWD-DWS-ADS](https://mp.weixin.qq.com/s?__biz=MzkyNTI5NTQ1NQ==&mid=2247510173&idx=1&sn=5a19751cf960e45af95989f82a534e2e&scene=58&subscene=0)
- [数仓(三)：分层设计 ODS-DWD-DWS-ADS](https://blog.csdn.net/qq_22473611/article/details/103278799)
- [数据仓库模型分层ODS、DWD、DWM实战](https://blog.csdn.net/ytp552200ytp/article/details/125526352?spm=1001.2014.3001.5502)
- [数仓建模分层概述](https://blog.csdn.net/ytp552200ytp/article/details/125277693?spm=1001.2014.3001.5502)

## 1 数仓建模的意义，为什么要对数据仓库分层？

只有数据模型将数据有序的组织和存储起来之后，大数据才能得到高性能、低成本、高效率、高质量的使用。

### 1.1 分层意义

**1）清晰数据结构**每一个数据分层都有它的作用域，这样我们在使用表的时候能更方便地定位和理解。

数据关系条理化：源系统间存在复杂的数据关系，比如客户信息同时存在于核心系统、信贷系统、理财系统、资金系统，取数时该如何决策呢？数据仓库会对相同主题的数据进行统一建模，把复杂的数据关系梳理成条理清晰的数据模型，使用时就可避免上述问题了。

**2）数据血缘追踪**简单来讲可以这样理解，我们最终给业务诚信的是一能直接使用的张业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围。

**3）数据复用，减少重复开发：**规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算。数据的逐层加工原则，下层包含了上层数据加工所需要的全量数据，这样的加工方式避免了每个数据开发人员都重新从源系统抽取数据进行加工。通过汇总层的引人，避免了下游用户逻辑的重复计算， 节省了用户的开发时间和精力，同时也节省了计算和存储。极大地减少不必要的数据冗余，也能实现计算结果复用，极大地降低存储和计算成本。

**4）把复杂问题简单化**讲一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。

**5）屏蔽原始数据的(影响) ，屏蔽业务的影响**业务或系统发生变化时，不必改一次业务就需要重新接入数据。提高数据稳定性和连续性。

屏蔽源头业务系统的复杂性：源头系统可能极为繁杂，而且表命名、字段命名 、字段含义等可能五花八门，通过 DW 层来规范和屏蔽所有这些复杂性，保证下游数据用户使用数据的便捷和规范。如果源头系统业务发生变更，相关的变更由 DW 层来处理，对下游用户透明，无须改动下游用户的代码和逻辑。

数据仓库的可维护性：分层的设计使得某一层的问题只在该层得到解决，无须更改下一层的代码和逻辑。

大数据系统需要数据模型方法来帮助更好地组织和存储数据，以便在性能、成本、效率和质量之间取得最佳平衡！

### 1.2 数据仓库（ETL）的四个操作

ETL(extractiontransformation loading)负责将分散的、异构数据源中的数据抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中。ETL 是实施数据仓库的核心和灵魂，ETL规则的设计和实施约占整个数据仓库搭建工作量的 60%～80%。

**1）数据抽取extraction**包括初始化数据装载和数据刷新：初始化数据装载主要关注的是如何建立维表、事实表，并把相应的数据放到这些数据表中；而数据刷新关注的是当源数据发生变化时如何对数据仓库中的相应数据进行追加和更新等维护(比如可以创建定时任务，或者触发器的形式进行数据的定时刷新)。

**2）数据清洗**主要是针对源数据库中出现的二义性、重复、不完整、违反业务或逻辑规则等问题的数据进行统一的处理。即清洗掉不符合业务或者没用的的数据。比如通过编写hive或者MR清洗字段中长度不符合要求的数据。

**3）数据转换transformation**主要是为了将数据清洗后的数据转换成数据仓库所需要的数据：来源于不同源系统的同一数据字段的数据字典或者数据格式可能不一样(比如A表中叫id,B表中叫ids)，在数据仓库中需要给它们提供统一的数据字典和格式，对数据内容进行归一化；另一方面，数据仓库所需要的某些字段的内容可能是源系统所不具备的，而是需要根据源系统中多个字段的内容共同确定。

**4）数据加载loading**是将最后上面处理完的数据导入到对应的存储空间里（hbase，mysql等）以方便给数据集市提供，进而可视化。

一般大公司为了数据安全和操作方便，都是自己封装的数据平台和任务调度平台，底层封装了大数据集群比如hadoop集群，spark集群，sqoop,hive,zookeepr,hbase等只提供web界面，并且对于不同员工加以不同权限，然后对集群进行不同的操作和调用。以数据仓库为例，将数据仓库分为逻辑上的几个层次。这样对于不同层次的数据操作，创建不同层次的任务，可以放到不同层次的任务流中进行执行（大公司一个集群通常每天的定时任务有几千个等待执行，甚至上万个，所以划分不同层次的任务流，不同层次的任务放到对应的任务流中进行执行，会更加方便管理和维护）。

**3、分层的误区**

数仓层内部的划分不是为了分层而分层，分层是为了解决 ETL 任务及工作流的组织、数据的流向、读写权限的控制、不同需求的满足等各类问题。

业界较为通行的做法将整个数仓层又划分成了 DWD、DWT、DWS、DIM、DM等很多层。然而我们却始终说不清楚这几层之间清晰的界限是什么，或者说我们能说清楚它们之间的界限，复杂的业务场景却令我们无法真正落地执行。

所以数据分层这块一般来说三层是最基础的，至于DW层如何进行切分，是根据具体的业务需求和公司场景自己去定义。

## 2 技术架构

![图片](https://img-blog.csdnimg.cn/img_convert/86650a1442f4c2fe96784b0d8e4a2d13.png)

![图片](https://img-blog.csdnimg.cn/img_convert/2919ada1447aacad4d153167cd4fc249.png)

数据中台包含的内容很多，对应到具体工作中的话，它可以包含下面的这些内容：

- **系统架构：**以Hadoop、Spark等组件为中心的架构体系
- **数据架构：**顶层设计，主题域划分，分层设计，ODS-DW-ADS
- **数据建模：**维度建模，业务过程-确定粒度-维度-事实表
- **数据管理：**资产管理，元数据管理、质量管理、主数据管理、数据标准、数据安全管理
- **辅助系统：**调度系统、ETL系统、监控系统
- **数据服务：**数据门户、机器学习数据挖掘、数据查询、分析、报表系统、可视化系统、数据交换分享下载

## 3 数仓分层架构

![图片](https://img-blog.csdnimg.cn/img_convert/185de47e66e5532fd4fa6d6c596b6e60.png)

数据仓库标准上可以分为四层。但是注意这种划分和命名不是唯一的，一般数仓都是四层，但是不同公司可能叫法不同。但是核心的理念都是从四层数据模型而来。

![图片](https://img-blog.csdnimg.cn/img_convert/30b10a0e2fd3aaa74378ff181015a794.png)

![图片](https://img-blog.csdnimg.cn/img_convert/1408e488f259724e5ac03dc5e92e27f0.png)

![图片](https://img-blog.csdnimg.cn/img_convert/2ed4caf1c21b1ef741297b1b115b337f.png)

### 3.1 贴源层（ODS, Operational Data Store）
![图片](https://img-blog.csdnimg.cn/img_convert/d2bdab5efa74768ad53707add89aa090.png)

数据引入层（ODS，Operational Data Store，又称数据基础层）：将原始数据几乎无处理地存放在数据仓库系统中，结构上与源系统基本保持一致，是数据仓库的数据准备区。这一层的主要职责是将基础数据同步、存储。

一般来说 ODS 层的数据和源系统的数据是同构的，主要目的是简化后续数据加工处理的工作。从数据粒度上来说 ODS 层的数据粒度是细的。ODS 层的表通常包括两类，一个用于存储当前需要加载的数据，一个用于存储处理完后的历史数据。历史数据一般保存 3-6 个月后需要清除，以节省空间。但不同的项目要区别对待，如果源系统的数据量不大，可以保留更长的时间，甚至全量保存。

注意：在这层，理应不是简单的数据接入，而是要考虑一定的数据清洗，比如异常字段的处理、字段命名规范化、时间字段的统一等，一般这些很容易会被忽略，但是却至关重要。特别是后期我们做各种特征自动生成的时候，会十分有用。

注意：有的公司ODS层不会做太多数据过滤处理,会放到DWD层来处理。有的公司会在一开始时就在ODS层做数据相对精细化的过滤.这个并没有明确规定,看每个公司自己的想法和技术规范。

一般企业开发时,都会对原始数据存入到ODS时,做一些最基本的处理。

**数据来源区分**

数据按照时间分区存储,一般是按照天,也有公司使用年、月、日三级分区做存储的。

进行最基本的数据处理,如格式错误的丢弃,关键信息丢失的过滤掉等等。

**数据实时离线**

- 离线方面：每日定时任务型：跑批任务，业务库，比如我们典型的日计算任务，这里经常会使用 Sqoop 来抽取，比如我们每天定时抽取一次。每天凌晨算前一天的数据，早上起来看报表。这种任务经常使用 Hive、Spark 来计算，最终结果写入 Hive、Hbase、Mysql、Es 或者 Redis 中。

- 实时数据：日志埋点数据或者业务库，这部分主要是各种实时的系统使用，比如我们的实时推荐、实时用户画像，一般我们会用 Spark Streaming、Flink 来计算，最后会落入 Es、Hbase 或者 Redis 中。数据源是业务数据库，可以考虑用 Canal 监听 Mysql 的 Binlog，实时接入即可，然后也是收集到消息队列中，最终再由 Camus 拉取到 HDFS。

**1）数据主要来源：**

- 数据源是业务数据库，公司所有的系统产生的数据

- 是通过在客户端埋点上报，收集用户的行为日志，以及一些后端日志的日志类型数据源。对于埋点行为日志来说，一般会经过一个这样的流程，首先数据会上报到 Nginx 然后经过 Flume 收集，然后存储到 Kafka 这样的消息队列，然后再由实时或者离线的一些拉取的任务，拉取到我们的离线数据仓库 HDFS

- 外部数据（包括合作数据以及爬虫获得的数据），将所采集的数据汇总到一起

**2）数据存储策略（增量、全量）**

实际应用中，可以选择采用增量、全量存储或拉链存储的方式。

- **增量存储**

为了满足历史数据分析需求，您可以在ODS层表中添加时间维度作为分区字段。以天为单位的增量存储，以业务日期作为分区，每个分区存放日增量的业务数据。

举例如下：

1月1日，用户A访问了A公司电商店铺B，A公司电商日志产生一条记录t1。1月2日，用户A又访问了A公司电商店铺C，A公司电商日志产生一条记录t2。

采用增量存储方式，t1将存储在1月1日这个分区中，t2将存储在1月2日这个分区中。

1月1日，用户A在A公司电商网购买了B商品，交易日志将生成一条记录t1。1月2日，用户A又将B商品退货了，交易日志将更新t1记录。

采用增量存储方式，初始购买的t1记录将存储在1月1日这个分区中，更新后的t1将存储在1月2日这个分区中。

交易、日志等事务性较强的ODS表适合增量存储方式。这类表数据量较大，采用全量存储的方式存储成本压力大。此外，这类表的下游应用对于历史全量数据访问的需求较小（此类需求可通过数据仓库后续汇总后得到）。例如，日志类ODS表没有数据更新的业务过程，因此所有增量分区UNION在一起就是一份全量数据。

- **全量存储**

以天为单位的全量存储，以业务日期作为分区，每个分区存放截止到业务日期为止的全量业务数据。

例如，1月1日，卖家A在A公司电商网发布了B、C两个商品，前端商品表将生成两条记录t1、t2。1月2日，卖家A将B商品下架了，同时又发布了商品D，前端商品表将更新记录t1，同时新生成记录t3。采用全量存储方式， 在1月1日这个分区中存储t1和t2两条记录，在1月2日这个分区中存储更新后的t1以及t2、t3记录。

对于小数据量的缓慢变化维度数据，例如商品类目，可直接使用全量存储。

- **拉链存储**

拉链存储通过新增两个时间戳字段（start_dt和end_dt），将所有以天为粒度的变更数据都记录下来，通常分区字段也是这两个时间戳字段。

![图片](https://img-blog.csdnimg.cn/img_convert/a7c7d87fff7adfb718da8de01253460f.png)

方案

概念：又称为接口层(stage)，用于存储每天的增量数据和变更数据

数据生成方式：直接从kafka接收源数据，需要业务表每天生成update,delete,inseret数据，只生成insert数据的业务表，数据直接入明细层。

讨论方案：只把canal日志直接入缓冲层，如果其它有拉链数据的业务，也入缓冲层。

日志存储方式：使用impala外表，parquet文件格式，方便需要MR处理的数据读取。

日志删除方式：长久存储，可只存储最近几天的数据。讨论方案：直接长久存储。

表schema：一般按天创建分区，partitioned by 一般都是按照天进行存放。

库与表命名。库名：ods,表名：初步考虑格式为ods日期业务表名,待定。

hive的外部表,对应的是业务表。

hive外部表,存放数据的文件可以不是在hive的hdfs默认的位置,并且hive对应的表删除时,相应的数据文件并不会被删除.这样对于企业开发来说,可以防止因为删除表的操作而把宝贵的数据删除掉hive的业务表,则相反.数据文件存放在hive对应的默认位置,表删除时,对应文件也会被删除掉。

### 3.2 数仓层（DW,data warehouse）

数据仓库层(DW)层：数据仓库层是我们在做数据仓库时要核心设计的一层，本层将从 ODS 层中获得的数据按照主题建立各种数据模型，每一个主题对应一个宏观的分析领域，数据仓库层排除对决策无用的数据，提供特定主题的简明视图。在DW层会保存BI系统中所有的历史数据，例如保存10年的数据。

DW存放明细事实数据、维表数据及公共指标汇总数据。其中，明细事实数据、维表数据一般根据ODS层数据加工生成。公共指标汇总数据一般根据维表数据和明细事实数据加工生成。

DW层又细分为维度层（DIM）、明细数据层（DWD）和汇总数据层（DWS），采用维度模型方法作为理论基础， 可以定义维度模型主键与事实模型中外键关系，减少数据冗余，也提高明细数据表的易用性。在汇总数据层同样可以关联复用统计粒度中的维度，采取更多的宽表化手段构建公共指标数据层，提升公共指标的复用性，减少重复加工。

维度层（DIM，Dimension）：以维度作为建模驱动，基于每个维度的业务含义，通过添加维度属性、关联维度等定义计算逻辑，完成属性定义的过程并建立一致的数据分析维表。为了避免在维度模型中冗余关联维度的属性，基于雪花模型构建维度表。

明细数据层（DWD，Data Warehouse Detail）：以业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细事实表。可将某些重要属性字段做适当冗余，也即宽表化处理。

汇总数据层（DWS，Data Warehouse Summary）：以分析的主题对象作为建模驱动，基于上层的应用和产品的指标需求，构建公共粒度的汇总指标表。以宽表化手段物理化模型，构建命名规范、口径一致的统计指标，为上层提供公共指标，建立汇总宽表、明细事实表。

主题域：面向业务过程，将业务活动事件进行抽象的集合，如下单、支付、退款都是业务过程。针对公共明细层（DWD）进行主题划分。

数据域：面向业务分析，将业务过程或者维度进行抽象的集合。针对公共汇总层（DWS） 进行数据域划分。

DWD 层是以业务过程为驱动。

DWS 层、DWT 层和 ADS 层都是以需求为驱动。

DWD：data warehouse details 数据明细层。主要对ODS数据层做一些数据清洗和规范化的操作。

数据清洗：去除空值、脏数据、枚举值转换，超过极限范围的。

DWB：data warehouse base 数据基础层，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。

DWS：data warehouse service 数据服务层，基于DWB上的基础数据，整合汇总成分析某一个主题域的服务数据层，一般是宽表。用于提供后续的业务查询，OLAP分析，数据分发等。

用户行为，轻度聚合

主要对ODS/DWD层数据做一些轻度的汇总。

#### 3.2.1 公共维度层（DIM，Dimension）

DIM：这一层比较单纯，举个例子就明白，比如国家代码和国家名、地理位置、中文名、国旗图片等信息就存在DIM层中。

基于维度建模理念思想，建立整个企业的一致性维度。降低数据计算口径和算法不统一风险。

公共维度汇总层（DIM）主要由维度表（维表）构成。维度是逻辑概念，是衡量和观察业务的角度。维表是根据维度及其属性将数据平台上构建的表物理化的表，采用宽表设计的原则。因此，构建公共维度汇总层（DIM）首先需要定义维度。

高基数维度数据：一般是用户资料表、商品资料表类似的资料表。数据量可能是千万级或者上亿级别。

低基数维度数据：一般是配置表，比如枚举值对应的中文含义，或者日期维表。数据量可能是个位数或者几千几万。

设计维表：

完成维度定义后，您就可以对维度进行补充，进而生成维表了。维表的设计需要注意：

建议维表单表信息不超过1000万条。

维表与其他表进行Join时，建议您使用Map Join。

避免过于频繁的更新维表的数据。缓慢变化维：拉链表

公共维度汇总层（DIM）维表规范

公共维度汇总层（DIM）维表命名规范：dim_{业务板块名称/pub}_{维度定义}[_{自定义命名标签}]，所谓pub是与具体业务板块无关或各个业务板块都可公用的维度，如时间维度。

例如：公共区域维表dim_pub_area 商品维表dim_asale_itm

事实表中一条记录所表达的业务细节程度被称为粒度。通常粒度可以通过两种方式来表述：一种是维度属性组合所表示的细节程度，一种是所表示的具体业务含义。通透！数据仓库领域常见建模方法及实例演示。

**建模方式及原则**

需要构建维度模型，一般采用星型模型，呈现的状态一般为星座模型（由多个事实表组合，维表是公共的，可被多个事实表共享）；

为支持数据重跑可额外增加数据业务日期字段，可按日进行分表，用增量ODS层数据和前一天DWD相关表进行merge处理？

粒度是一行信息代表一次行为，例如一次下单。

**维度建模步骤**

选择业务过程：在业务系统中，挑选感兴趣的业务线，比如下单业务，支付业务，退款业务，物流业务，一条业务线对应一张事实表。如果是中小公司，尽量把所有业务过程都选择。DWD如果是大公司（1000多张表），选择和需求相关的业务线。

声明粒度：数据粒度指数据仓库的数据中保存数据的细化程度或综合程度的级别。声明粒度意味着精确定义事实表中的一行数据表示什么，应该尽可能选择最小粒度，以此来应各种各样的需求。典型的粒度声明如下：订单当中的每个商品项作为下单事实表中的一行，粒度为每次。每周的订单次数作为一行，粒度为每周。每月的订单次数作为一行，粒度为每月。如果在DWD层粒度就是每周或者每月，那么后续就没有办法统计细粒度的指标了。所以建议采用最小粒度。

确定维度：维度的主要作用是描述业务是事实，主要表示的是“谁，何处，何时”等信息。确定维度的原则是：后续需求中是否要分析相关维度的指标。例如，需要统计，什么时间下的订单多，哪个地区下的订单多，哪个用户下的订单多。需要确定的维度就包括：时间维度、地区维度、用户维度。维度表：需要根据维度建模中的星型模型原则进行维度退化。

确定事实：此处的“事实”一词，指的是业务中的度量值（次数、个数、件数、金额，可以进行累加），例如订单金额、下单次数等。在DWD层，以业务过程为建模驱动，基于每个具体业务过程的特点，构建最细粒度的明细层事实表。事实表可做适当的宽表化处理。

注意：DWD层是以业务过程为驱动。DWS层、DWT层和ADS层都是以需求为驱动，和维度建模已经没有关系了。DWS和DWT都是建宽表，按照主题去建表。主题相当于观察问题的角度。对应着维度表。

关于主题：

数据仓库中的数据是面向主题组织的，主题是在较高层次上将企业信息系统中的数据进行综合、归类和分析利用的一个抽象概念，每一个主题基本对应一个宏观的分析领域。如财务分析就是一个分析领域，因此这个数据仓库应用的主题就为“财务分析”。

关于主题域：

主题域通常是联系较为紧密的数据主题的集合。可以根据业务的关注点，将这些数据主题划分到不同的主题域(也说是对某个主题进行分析后确定的主题的边界)

关于主题域的划分：

主题域的确定必须由最终用户（业务）和数据仓库的设计人员共同完成的， 而在划分主题域时，大家的切入点不同可能会造成一些争论、重构等的现象，考虑的点可能会是下方的某些方面：

- 按照业务或业务过程划分：比如一个靠销售广告位置的门户网站主题域可能会有广告域，客户域等，而广告域可能就会有广告的库存，销售分析、内部投放分析等主题；

- 根据需求方划分：比如需求方为财务部，就可以设定对应的财务主题域，而财务主题域里面可能就会有员工工资分析，投资回报比分析等主题；

- 按照功能或应用划分：比如微信中的朋友圈数据域、群聊数据域等，而朋友圈数据域可能就会有用户动态信息主题、广告主题等；

- 按照部门划分：比如可能会有运营域、技术域等，运营域中可能会有工资支出分析、活动宣传效果分析等主题；

总而言之，切入的出发点逻辑不一样，就可以存在不同的划分逻辑。在建设过程中可采用迭代方式，不纠结于一次完成所有主题的抽象，可先从明确定义的主题开始，后续逐步归纳总结成自身行业的标准模型。

主题：当事人、营销、财务、合同协议、机构、地址、渠道、 产品、

金融业务主题有哪些 ：可分为四个主题：

- 用户主题（用户年龄、性别、收货地址、电话、省份等）
- 交易主题（订单数据、账单数据等）
- 风控主题（用户的风控等级，第三方征信数据）
- 营销主题（营销活动名单，活动配置信息等）

#### 3.2.2 DWD（data warehouse detail）数据明细层，明细粒度事实层

![图片](https://img-blog.csdnimg.cn/img_convert/71ad981f8099ca261b6170b2d000e157.png)

DWD是业务层与数据仓库的隔离层， 这一层主要解决一些数据质量问题和数据的完整度问题。

明细表用于存储ODS层原始表转换过来的明细数据，DWD 层的数据应该是一致的、准确的、干净的数据，即对源系统数据ODS层数据进行清洗（去除空值，脏数据，超过极限范围的数据，行式存储改为列存储，改压缩格式）、规范化、维度退化、脱敏等操作。比如用户的资料信息来自于很多不同表，而且经常出现延迟丢数据等问题，为了方便各个使用方更好的使用数据，我们可以在这一层做一个屏蔽。这一层也包含统一的维度数据。

明细粒度事实层（DWD）：以业务过程作为建模驱动，基于每个具体的业务过程特点，构建最细粒度的明细层事实表。可以结合企业的数据使用特点，将明细事实表的某些重要维度属性字段做适当冗余，即宽表化处理。明细粒度事实层的表通常也被称为逻辑事实表。

负责数据的最细粒度的数据，在DWD层基础上，进行轻度汇总，结合常用维度（时间，地点，组织层级，用户，商品等）

该层一般保持和ODS层一样的数据粒度，并且提供一定的数据质量保证，在ODS的基础上对数据进行加工处理，提供更干净的数据。同时，为了提高数据明细层的易用性，该层会采用一些维度退化手法，当一个维度没有数据仓库需要的任何数据时，就可以退化维度，将维度退化至事实表中，减少事实表和维表的关联。

例如：

订单id,这种量级很大的维度，没必要用一张维度表来进行存储，而我们一般在进行数据分析时订单id又非常重要，所以我们将订单id冗余在事实表中，这种维度就是退化维度。

这一层的数据一般是遵循数据库第三范式或者维度建模，其数据粒度通常和 ODS 的粒度相同。在 PDW 层会保存 BI 系统中所有的历史数据，例如保存10年的数据。

数据在装入本层前需要做以下工作：去噪、去重、提脏、业务提取、单位统一、砍字段、业务判别。

清洗的数据种类：

- 不完整数据
- 错误数据
- 重复的数据

数据清洗的任务是过滤那些不符合要求的数据，将过滤的结果交给业务主管部门，确认是否过滤掉还是由业务单位修正之后再进行抽取。

**DWD层做了哪些事？**

**①数据清洗过滤**

去除废弃字段,去除格式错误的信息

去除丢失了关键字段的信息

过滤核心字段无意义的数据，比如订单表中订单id为null，支付表中支付id为空

对手机号、身份证号等敏感数据脱敏

去除不含时间信息的数据(这个看公司具体业务,但一般数据中都会带上时间戳,这样方便后续处理时,进行时间维度上信息分析处理和提取)

有些公司还会在这一层将数据打平,不过这具体要看业务需求.这是因为kylin适合处理展平后数据,不适合处理嵌套的表数据信息

有些公司还会将数据session做切割,这个一般是app的日志数据,其他业务场景不一定适合.这是因为app有进入后台模式,例如用户上午打开app用了10分钟,然后app切入后台,晚上再打开,这时候session还是一个,实际上应该做切割才对.(也有公司会记录app进入后台,再度进入前台的记录,这样来做session切割)

**②数据映射,转换**

将GPS经纬度转换为省市区详细地址。业界常见GPS快速查询一般将地理位置知识库使用geohash映射,然后将需要比对的GPS转换为geohash后跟知识库中geohash比对,查找出地理位置信息当然,也有公司使用open api,如高德地图,百度地图的api进行GPS和地理位置信息映射,但这个达到一定次数需要花钱,所以大家都懂的

会将IP地址也转换为省市区详细地址。这个有很多快速查找库,不过基本原理都是二分查找,因为ip地址可以转换为长整数.典型的如ip2region库

将时间转换为年,月,日甚至周,季度维度信息

数据规范化,因为大数据处理的数据可能来资源公司不同部门,不同项目,不同客户端,这时候可能相同业务数据字段,数据类型,空值等都不一样,这时候需要在DWD层做抹平.否则后续处理使用时,会造成很大的困扰

如boolean,有使用0 1标识,也有使用true false标识的

如字符串空值,有使用"",也有使用null,的,统一为null即可

如日期格式,这种就差异性更大,需要根据实际业务数据决定,不过一般都是格式化为YYYY-MM-dd HH:mm:ss 这类标准格式

维度退化：对业务数据传过来的表进行维度退化和降维。（商品一级二级三级、省市县、年月日）订单id冗余在事实表

清洗掉多少数据算合理：1万条数据清洗掉1条。

合理表数：一万张表变为三千张表，三千张表变为一千张表

**明细粒度事实表设计原则：**

- 一个明细粒度事实表仅和一个维度关联。
- 尽可能包含所有与业务过程相关的事实 。
- 只选择与业务过程相关的事实。
- 分解不可加性事实为可加的组件。
- 在选择维度和事实之前必须先声明粒度。
- 在同一个事实表中不能有多种不同粒度的事实。
- 事实的单位要保持一致。粒度
- 谨慎处理Null值。
- 使用退化维度提高事实表的易用性。

方案

讨论方案：数据的合成方式为：

全量：每天把明细层的前天全量数据和昨天新数据合成一个新的数据表，覆盖旧表。同时使用历史镜像，按周/按月/按年存储一个历史镜像到新表。

日志存储方式：直接数据使用impala外表，parquet文件格式， 建议使用内表，下面几层都是从impala生成的数据，建议都用内表+静态/动态分区。

表schema：一般按天创建分区，没有时间概念的按具体业务选择分区字段。partitioned by 一般都是按照天进行存放。

库与表命名。库名：dwd,表名：初步考虑格式为dwd日期业务表名,待定。

旧数据更新方式：直接覆盖

明细粒度事实层（DWD）规范

命名规范为：dwd_{业务板块/pub}_{数据域缩写}_{业务过程缩写}[_{自定义表命名标签缩写}] _{单分区增量全量标识}，pub表示数据包括多个业务板块的数据。单分区增量全量标识通常为：i表示增量，f表示全量。

例如：dwd_asale_trd_ordcrt_trip_di（A电商公司航旅机票订单下单事实表，日刷新增量） dwd_asale_itm_item_df（A电商商品快照事实表，日刷新全量）。

本教程中，DWD层主要由三个表构成：

- 交易商品信息事实表：dwd_asale_trd_itm_di。
- 交易会员信息事实表：ods_asale_trd_mbr_di。
- 交易订单信息事实表：dwd_asale_trd_ord_di。

![图片](https://img-blog.csdnimg.cn/img_convert/abd47a0c11fd683725c8ea6d4af30077.png)

```sql
CREATE TABLE IF NOT EXISTS dwd_asale_trd_itm_di
(
item_id BIGINT COMMENT '商品ID',
item_title STRING COMMENT '商品名称',
item_price DOUBLE COMMENT '商品价格',
item_stuff_status BIGINT COMMENT '商品新旧程度_0全新1闲置2二手',
item_prov STRING COMMENT '商品省份',
item_city STRING COMMENT '商品城市',
cate_id BIGINT COMMENT '商品类目ID',
cate_name STRING COMMENT '商品类目名称',
commodity_id BIGINT COMMENT '品类ID',
commodity_name STRING COMMENT '品类名称',
buyer_id BIGINT COMMENT '买家ID',
)
COMMENT '交易商品信息事实表'
PARTITIONED BY (ds STRING COMMENT '日期')
LIFECYCLE 400;
```

![图片](https://img-blog.csdnimg.cn/img_convert/8dba41de076830c9f60f6f8e6c70643b.png)

#### 3.3.3 DWS（ data warehouse service）数据服务层，汇总层宽表



![图片](https://img-blog.csdnimg.cn/img_convert/af6caa5f788ea44f94bdd46445f8994b.png)

基于 DWD 明细数据层，我们会按照一些分析场景、分析实体等去组织我们的数据，组织成一些分主题的汇总数据层 DWS。

明细粒度 ==> 汇总粒度

DWS层（数据汇总层）宽表，面向主题的汇总，维度相对来说比较少，DWS是根据DWD层基础数据按各个维度ID进行粗粒度汇总聚合，如按交易来源，交易类型进行汇合。整合汇总成分析某一个主题域的服务数据，一般是宽表。

以DWD为基础，按天进行轻度汇总。统计各个主题对象的当天行为，（例如，购买行为，统计商品复购率）。

该层数据表会相对比较少，大多都是宽表(一张表会涵盖比较多的业务内容，表中的字段较多)。按照主题划分，如订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。

融合多个中间层数据，基于主题形成事实表，比如用户事实表、渠道事实表、终端事实表、资产事实表等等，事实表一般是宽表，在本层上实现企业级数据的一致性。

首先划分业务主题，将主题划分为销售域、库存域、客户域、采购域 等，其次就是 确定每个主题域的事实表和维度表。通常根据业务需求，划分成流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。

最近一天某个类目（例如：厨具）商品在各省的销售总额、该类目Top10销售额商品名称、各省用户购买力分布。因此，我们可以以最终交易成功的商品、类目、买家等角度对最近一天的数据进行汇总。

比如用户每个时间段在不同登录ip购买的商品数等。这里做一层轻度的汇总会让计算更加的高效，在此基础上如果计算仅7天、30天、90天的行为的话会快很多。我们希望80%的业务都能通过我们的DWS层计算，而不是ODS。

**DWS层做了哪些事？**

dws将dwd层的数据按主题进行汇总，按照主题放到一个表中，

比如用户主题下会将用户注册信息、用户收货地址、用户的征信数据放到同一张表中，而这些在dwd层是对应多张表的,按照业务划分，如流量、订单、用户等，生成字段比较多的宽表

主题建模,围绕某一个业务主题进行数据建模,将相关数据抽离提取出来.

如：

- 将流量会话按照天,月进行聚合
- 将每日新用户进行聚合
- 将每日活跃用户进行聚合
- 维度建模,其实也差不多,不过是根据业务需要,提前将后续数据查询处理需要的维度数据抽离处理出来,方便后续查询使用.
- 如将运营位维度数据聚合
- 将渠道拉新维度数据聚合

①DWS层每个主题1-3张宽表（处理100-200个指标 70%以上的需求）

具体宽表名称：用户行为宽表，用户购买商品明细行为宽表，商品宽表， 物流宽表、 售后等。

②哪个宽表最宽？大概有多少个字段？

最宽的是用户行为宽表。大概有60-200个字段

③具体用户行为宽表字段名称

评论、打赏、收藏、关注--商品、关注--人、点赞、分享、好价爆料、文章发布、活跃、签到、补签卡、幸运屋、礼品、金币、电商点击、gmv

④分析过的指标

日活、月活、周活、留存、留存率、新增（日、周、年）、转化率、流失、回流、七天内连续 3 天登录（点赞、收藏、评价、购买、加购、下单、活动）、连续 3 周（月）登录、GMV（成交金额，下单）、复购率、复购率排行、点赞、评论、收藏、领优惠价人数、使用优惠价、沉默、值不值得买、退款人数、退款率 topn 热门商品

- 活跃

日活：100 万 ；月活：是日活的 2-3 倍 300 万

总注册的用户多少？1000 万-3000 万之间

- GMV，哪个商品卖的最好？每天下单量多少？

GMV：每天 10 万订单 （50 – 100 元） 500 万-1000 万

100万的日活每天大概有10万人购买，平均每人消费100元，一天的GMV在1000万

10%-20% 100 万-200 万

- 复购率

某日常商品复购；（手纸、面膜、牙膏）10%-20%

电脑、显示器、手表 1%

- 转化率

商品详情 =》 加购物车 =》下单 =》 支付

5%-10% 60-70% 90%-95%

- 留存率

1/2/3、周留存、月留存

搞活动：10-20%

方案：

概念：又称数据集市或宽表。按照业务划分，如流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。

数据生成方式：由轻度汇总层和明细层数据计算生成。

日志存储方式：使用impala内表，parquet文件格式。

表schema：一般按天创建分区，没有时间概念的按具体业务选择分区字段。

库与表命名。库名：dws, 表名：初步考虑格式为：dws日期业务表名,待定。

旧数据更新方式：直接覆盖

**公共汇总事实表规范**

公共汇总事实表命名规范：dws_{业务板块缩写/pub}_{数据域缩写}_{数据粒度缩写}[_{自定义表命名标签缩写}]_{统计时间周期范围缩写}。关于统计实际周期范围缩写，缺省情况下，离线计算应该包括最近一天（_1d），最近N天（_nd）和历史截至当天（_td）三个表。如果出现_nd的表字段过多需要拆分时，只允许以一个统计周期单元作为原子拆分。即一个统计周期拆分一个表，例如最近7天（_1w）拆分一个表。不允许拆分出来的一个表存储多个统计周期。

对于小时表（无论是天刷新还是小时刷新），都用_hh来表示。对于分钟表（无论是天刷新还是小时刷新），都用_mm来表示。

举例如下：

dws_asale_trd_byr_subpay_1d（买家粒度交易分阶段付款一日汇总事实表）

dws_asale_trd_byr_subpay_td（买家粒度分阶段付款截至当日汇总表）

dws_asale_trd_byr_cod_nd（买家粒度货到付款交易汇总事实表）

dws_asale_itm_slr_td（卖家粒度商品截至当日存量汇总表）

dws_asale_itm_slr_hh（卖家粒度商品小时汇总表）---维度为小时

dws_asale_itm_slr_mm（卖家粒度商品分钟汇总表）---维度为分钟

- 用户维度：用户主题

```sql
drop table
if exists dws_sale_detail_daycount;
create external table dws_sale_detail_daycount(
user_id string comment '用户 id',
--用户信息
user_gender string comment '用户性别',
user_age string comment '用户年龄',
user_level string comment '用户等级',
buyer_nick string comment '买家昵称',
mord_prov string comment '地址',
--下单数、 商品数量， 金额汇总
login_count bigint comment '当日登录次数',
cart_count bigint comment '加入购物车次数',
order_count bigint comment '当日下单次数',
order_amount decimal(16,2) comment '当日下单金额',
payment_count bigint comment '当日支付次数',
payment_amount decimal(16,2) comment '当日支付金额',
confirm_paid_amt_sum_1d double comment '最近一天订单已经确认收货的金额总和'
order_detail_stats array<struct<sku_id:string,sku_num:bigint,order_count:bigint,order_amount:decimal(20,2)>> comment '下单明细统计'


) comment '每日购买行为'
partitioned by(`dt`
string)
stored as parquet
location '/warehouse/gmall/dws/dws_sale_detail_daycount/'
tblproperties("parquet.compression" = "lzo");
```

- 商品维度：商品主题

```sql
CREATE TABLE IF NOT EXISTS dws_asale_trd_itm_ord_1d
(
item_id BIGINT COMMENT '商品ID',
--商品信息，产品信息
item_title STRING COMMENT '商品名称',
cate_id BIGINT COMMENT '商品类目ID',
cate_name STRING COMMENT '商品类目名称',
--mord_prov STRING COMMENT '收货人省份',
--商品售出金额汇总
confirm_paid_amt_sum_1d DOUBLE COMMENT '最近一天订单已经确认收货的金额总和'
)
COMMENT '商品粒度交易最近一天汇总事实表'
PARTITIONED BY (ds STRING COMMENT '分区字段YYYYMMDD')
LIFECYCLE 36000;
```

![图片](https://img-blog.csdnimg.cn/img_convert/999cf3c9173809e9ee1aa83b955977da.png)

问：数据集市层是不是没地方放了，各个业务的数据集市表是应该在 dws 还是在 app?

答：这个问题不太好回答，我感觉主要就是明确一下数据集市层是干什么的，如果你的数据集市层放的就是一些可以供业务方使用的宽表，放在 app 层就行。如果你说的数据集市层是一个比较泛一点的概念，那么其实 dws、dwd、app 这些合起来都算是数据集市的内容。

### 3.3 应用层（ADS）applicationData Service应用数据服务

![图片](https://img-blog.csdnimg.cn/img_convert/9a88b03266e20bd6abdd4dfbc1a9a530.png)

数据应用层（ADS，Application Data Store）：存放数据产品个性化的统计指标数据，报表数据。主要是提供给数据产品和数据分析使用的数据，通常根据业务需求，划分成流量、订单、用户等，生成字段比较多的宽表，用于提供后续的业务查询，OLAP分析，数据分发等。从数据粒度来说，这层的数据是汇总级的数据，也包括部分明细数据。从数据的时间跨度来说，通常是DW层的一部分，主要的目的是为了满足用户分析的需求，而从分析的角度来说，用户通常只需要分析近几年的即可。从数据的广度来说，仍然覆盖了所有业务数据。

在 DWS 之上，我们会面向应用场景去做一些更贴近应用的 APP 应用数据层，这些数据应该是高度汇总的，并且能够直接导入到我们的应用服务去使用。

应用层(ADS)：应用层主要是各个业务方或者部门基于DWD和DWS建立的数据集市(Data Market, DM)，一般来说应用层的数据来源于DW层，而且相对于DW层，应用层只包含部门或者业务方面自己关心的明细层和汇总层的数据。

该层主要是提供数据产品和数据分析使用的数据。一般就直接对接OLAP分析,或者业务层数据调用接口了

数据应用层APP：面向业务定制的应用数据主要提供给数据铲平和数据分析使用的数据，一般会放在ES，MYSQL，Oracle，Redis等系统供线上系统使用，也可以放在Hive 或者 Druid 中供数据分析和数据挖掘使用。

APP 层：为应用层，这层数据是完全为了满足具体的分析需求而构建的数据，也是星形或雪花结构的数据。如我们经常说的报表数据，或者说那种大宽表，一般就放在这里。包括前端报表、分析图表、KPI、仪表盘、OLAP、专题等分析，面向最终结果用户；

概念：应用层是根据业务需要，由前面三层数据统计而出的结果，可以直接提供查询展现，或导入至Mysql中使用。

数据生成方式：由明细层、轻度汇总层，数据集市层生成，一般要求数据主要来源于集市层。

日志存储方式：使用impala内表，parquet文件格式。

表schema：一般按天创建分区，没有时间概念的按具体业务选择分区字段。

库与表命名。库名：暂定ads，另外根据业务不同，不限定一定要一个库。

旧数据更新方式：直接覆盖。

ADS 层复购率统计

![图片](https://img-blog.csdnimg.cn/img_convert/973b67f415056c4514150827de960205.png)



```sql
CREATE TABLE app_usr_interact( user_id string COMMENT '用户id',
nickname string COMMENT '用户昵称',
register_date string COMMENT '注册日期',
register_from string COMMENT '注册来源',
remark string COMMENT '细分渠道',
province string COMMENT '注册省份',
pl_cnt bigint COMMENT '评论次数',
ds_cnt bigint COMMENT '打赏次数',
sc_add bigint COMMENT '添加收藏',
sc_cancel bigint COMMENT '取消收藏',
gzg_add bigint COMMENT '关注商品',
gzg_cancel bigint COMMENT '取消关注商品',
gzp_add bigint COMMENT '关注人',
gzp_cancel bigint COMMENT '取消关注人',
buzhi_cnt bigint COMMENT '点不值次数',
zhi_cnt bigint COMMENT '点值次数',
zan_cnt bigint COMMENT '点赞次数',
share_cnts bigint COMMENT '分享次数',
bl_cnt bigint COMMENT '爆料数',
fb_cnt bigint COMMENT '好价发布数',
online_cnt bigint COMMENT '活跃次数',
checkin_cnt bigint COMMENT '签到次数',
fix_checkin bigint COMMENT '补签次数',
house_point bigint COMMENT '幸运屋金币抽奖次数',
house_gold bigint COMMENT '幸运屋积分抽奖次数',
pack_cnt bigint COMMENT '礼品兑换次数',
gold_add bigint COMMENT '获取金币',
gold_cancel bigint COMMENT '支出金币',
surplus_gold bigint COMMENT '剩余金币',
event bigint COMMENT '电商点击次数',
gmv_amount bigint COMMENT 'gmv',
gmv_sales bigint COMMENT '订单数'
)
PARTITIONED BY( dt string)
--stat_dt
date COMMENT '互动日期',
```

①如何分析用户活跃？

在启动日志中统计不同设备 id 出现次数。

②如何分析用户新增?

用活跃用户表 left join 用户新增表，用户新增表中 mid 为空的即为用户新增。

③如何分析用户 1 天留存？

留存用户=前一天新增 join 今天活跃

用户留存率=留存用户/前一天新增

④如何分析沉默用户？

(登录时间为 7 天前,且只出现过一次)

按照设备 id 对日活表分组，登录次数为 1，且是在一周前登录。

⑤如何分析本周回流用户？

本周活跃 left join 本周新增 left join 上周活跃，且本周新增 id 和上周活跃 id 都为 null。

⑥如何分析流失用户？

(登录时间为 7 天前)

按照设备 id 对日活表分组，且七天内没有登录过。

⑦如何分析最近连续 3 周活跃用户数？

按照设备 id 对周活进行分组，统计次数大于 3 次。

⑧如何分析最近七天内连续三天活跃用户数？

- 查询出最近 7 天的活跃用户，并对用户活跃日期进行排名
- 计算用户活跃日期及排名之间的差值
- 对同用户及差值分组，统计差值个数
- 将差值相同个数大于等于 3 的数据取出，然后去重，即为连续 3 天及以上活跃的用户

7 天连续收藏、点赞、购买、加购、付款、浏览、商品点击、退货

1 个月连续 7 天

连续两周

TMP：每一层的计算都会有很多临时表，专设一个DW TMP层来存储我们数据仓库的临时表。

### 3.4 层次调用规范

- 禁止反向调用
- ODS 只能被 DWD 调用。
- DWD 可以被 DWS 和 ADS 调用。
- DWS 只能被 ADS 调用。
- 数据应用可以调用 DWD、DWS、ADS，但建议优先考虑使用汇总度高的数据。
- ODS->DWD->DWS>ADS
- ODS->DWD->ADS

## 4 ODS层设计概要

- [数据仓库之ODS层设计概要](https://blog.csdn.net/ytp552200ytp/article/details/118610274)

### 4.1 ODS层的设计思路

#### 4.1.1 ODS层数据同步

上文提到ODS的数据来源于业务系统，且ODS落地的系统通常和业务系统是不同的，比如常见的将数据落到Hive中。所以，首先我们就需要将业务系统的数据抽取到ODS表中。一般来说，数据同步的方式大概可以分为三大类：**文件抽取**、**数据库表的抽取**和**原始日志的抽取**。

#### 4.1.2 文件抽取

通常情况下，ODS层表的存储位置与业务系统表的存储位置是不一样的，比如业务表存在MySQL中，而ODS层存储在Hive中。另外，有的时候，ODS层需要对接多个不同类型的业务系统库，比如DB2、Oracle、Mysql等等，一种比较简单实用的做法是和各个业务系统约定好数据接口，并让业务系统按照数据接口格式生成数据文件和完结标示文件给到ODS。

这种方式有两个明显的优势：一方面可以降低ODS处理多种类型数据库系统能力需求，另一方面也减少了对业务系统的性能影响。但是这种方式也存在一些不足：数据的抽取过程和加载过程是分开的，由业务系统和ODS分别负责，同时接口新增和变更比较麻烦，需要较大的沟通维护成本，另外，数据落地到文件增加了额外的上传下载工作，会造成效率比较低。

在实际的生产过程中，这种方式的数据同步也很少被使用。

#### 4.1.3 直连同步

直连同步是指通过定义好的规范接口API和基于动态链接库的方式直接连接业务库，比如ODBC/JDBC等规定了统一的标准接口，不同的数据库基于这套标准提供规范的驱动，从而支持完全相同的函数调用和SQL实现。比如经常使用的Sqoop就是采取这种方式进行批量数据同步的。

直连同步的方式配置十分简单，很容易上手操作，比较适合操作型业务系统的数据同步，但是会存在以下问题：

- 数据同步时间：随着业务规模的增长，数据同步花费的时间会越来越长，无法满足下游数仓生产的时间要求。

- 性能瓶颈：直连数据库查询数据，对数据库影响非常大，容易造成慢查询，如果业务库没有采取主备策略，则会影响业务线上的正常服务，如果采取了主备策略，虽然可以避免对业务系统的性能影响，但当数据量较大时，性能依然会很差。

- 抽取增量数据需要依靠修改业务系统，新增时间戳字段，并且按时间戳增量抽取的数据准确性不能得到保障，业务系统做数据补丁不更新时间戳字段将会导致漏数；

- 实时性差，只能在某个时刻抽取数据，不能满足准实时数据需求；

在实际的生产过程中，这种方式的数据同步经常被使用，值得注意的是：数据库直连抽取比较适用于小批量表的数据抽取，对于大批量的数据而言，性能会比较差。

#### 4.1.4 日志解析

据库日志抽取是指通过分析数据库日志，将业务系统的DDL和DML语句在一个镜像系统还原，并通过数据流的方式对外提供实时数据服务。

所谓日志解析，即解析数据库的变更日志，比如MySQL的Binlog日志，Oracle的归档日志文件。通过读取这些日志信息，收集变化的数据并将其解析到目标存储中即可完成数据的实时同步。这种读操作是在操作系统层面完成的，不需要通过数据库，因此不会给源数据库带来性能上的瓶颈。

由于是数据库日志抽取是获取所有的变更记录，落地到ODS表的时候我们需要根据主键去重按照日志时间倒排序获取最后状态的变化情况。通常使FULL OUTER JOIN全外连接的方式进行Merge数据。

数据库日志解析的同步方式可以实现实时与准实时的同步，延迟可以控制在毫秒级别的，其最大的优势就是性能好、效率高，不会对源数据库造成影响，目前，从业务系统到数据仓库中的实时增量同步，广泛采取这种方式。

当然，任何方式都不是完美的，使用日志解析的方式进行数据同步也会存在一些已知的问题：比如在业务系统做批量补数时会造成数据更新量超过处理的能力，从而导致数据延迟。另外，这种方式需要额外补数一个实时抽取的系统，从而也增加了投入和处理的复杂性。

#### 4.1.5 该如何选择同步方式

在实际的生产环境中，直连同步和日志解析是非常普遍的两种数据同步方式，随着实时技术的发展，使得实时数据同步的方式变得越来越方便，越来越多的企业开始尝试使用日志解析的方式进行数据同步。这里需要注意的是，每种方式都有其优缺点及适用的场景，找到合适的方式就是最好的方式，切不可一味的追求狂拽酷炫的同步技术，这也是很多技术人员经常犯的错误，应用和钻研新技术是技术人的追求，但是过犹不及，在解决具体问题的时候，要多方面权衡。

另外，数仓的建设是为业务服务的，应该把时间和精力放在如何支持业务、如何发挥数仓的价值、如何用数据为业务提供支持决策上来。笔者认为，数仓的建设不是一堆大数据技术的简单堆砌，深入理解业务和数据才是数仓建设的第一要义。

#### 4.1.6 ODS层数据清洗

关于ODS层是否做数据清洗一直是存在争议的，但有一点是可以确定的，对于比较重的清洗工作是要留到后面数仓的ETL过程中进行处理。

但是，有这么一种情况：我们在长期的生产实际过程中，发现部分已知的数据问题的处理可以通过自动化的方式来处理，这种方式通常在数据入库之前，做额外的加工处理后再做入库操作。

数据清洗的主要工作是处理那些不符合要求的数据，从而提升数据质量，比如一些常见的问题：错误的数据、重复的数据

- 错误的数据
  这种错误通常是业务系统处理不够健全造成的，比如字符串数据后面有回车空格、日期格式不正确、日期越界等等，这些问题如果不在ODS层做处理，后续的解析处理过程中也是要留意处理的

- 重复的数据
  例如，一些前端系统迁移过后的新老表融合可能会存在大量的重复历史数据，这也可以在数据清洗这一步骤中完成消除重复数据的操作。需要注意的是，在数据清洗后还需要对ODS的数据做稽核，还需要对脏数据做稽核校验，脏数据的校验主要集中在数据量上，如果数据量波动特别大则需要人工介入处理。

其实，在大多数的情况下，是不需要做数据清洗处理的，可以把这个清洗环节放到后面的明细层ETL中进行处理。

#### 4.1.7 ODS层表设计

通常而言，ODS层表跟业务系统保持一致，但又不完全等同于业务系统。在设计ODS物理表时，在**表命名**、**数据存储**等方面都需要遵循一定的准则。

#### 4.1.8 命名

比如：不管是表命名还是字段命名尽量和业务系统保持一致，但是需要通过额外的标识来区分增量和全量表，”_delta”来标识该表为增量表。

#### 4.1.9 存储

另外，为了满足历史数据分析需求，我们需要在ODS表中加一个时间维度，这个维度通常在ODS表中作为分区字段。如果是增量存储，则可以按天为单位使用业务日期作为分区，每个分区存放日增量的业务数据。如果是全量存储，只可以按天为单位使用业务日期作为分区，每个分区存储截止到当前业务时间的全量快照数据。

### 4.2 ODS层常见的问题

实时和准实时数据需求、数据飘移处理、巨型数据量表处理、如何有效控制数据存储。

#### 4.2.1 实时性

实时数据仓库的主要思想就是：在数据仓库中，将保存的数据分为两类，一种为静态数据，一种为动态数据，静态数据满足用户的查询分析要求；而动态数据就是为了适应实时性，数据源中发生的更新可以立刻传送到数据仓库的动态数据中，再经过响应的转换，满足实时的要求。

由于实时处理的特殊性及复杂性，很多情况下实时分析是建立在ODS上而不是数据仓库上，因为ODS处理逻辑简单，数据链路相对较短，产出更快。

根据表的刷新频率，可以将ODS层的表分为三大类：

- 实时ODS
  接近实时地与业务库的数据保持同步刷新，主要用于实时分析计算，比如实时的反欺诈，天猫双11实时大屏等等。这类表的ETL是实时进行的，一般情况下，这类表会存储在消息中间件中，比如Kafka，指的注意的是：**要求涉及的业务过程不能过多，处理的业务逻辑不能过于复杂**。这类ODS的表一般只是用于实时计算，相比批处理的表而言，其维护成本是相对较高的。

- 准实时ODS
  例如15分钟到1小时刷新一次,这类ODS比实时ODS成本要低些，基本可以满足大部分的准实时需求。并且可以根据实际需求调整刷新频率，具有较好的灵活性。在做处理这类准实时的ODS表时，需要特别注意ETL任务的产出效率，通常这类任务的产出时间最多不能超过ODS表的刷新周期时间。例如小时级别的表，任务不能超过1个小时。

- 传统ODS
  这是离线数仓最常见的一种表，即T+1，其数据一天刷新一次,可以利用业务系统的空闲时间进行刷新（通常是每天凌晨0-2点）,可实现所有业务系统的数据集成和刷新。刷新频率的下降也给系统有更多的时间进行数据更正和清洗。该类ODS层的表是最容易维护的。

#### 4.2.2 数据漂移

所谓数据漂移，指的是这样一种现象：ODS表的同一个业务日期数据中包含前一天或后一天凌晨附近的数据或者丢失当天的变更数据。

由于ODS需要承接面向历史的细节数据查询需求，这就需要物理落地到数据仓库的ODS表按时间段来切分进行分区存储，通常的做法是按某些时间戳字段来切分，实际往往由于时间戳字段的准确性问题导致数据飘移问题的发生。

一般情况下，我们使用的时间戳分为三类：

- 数据库表中用来标示数据记录更新的时间戳字段（即数据记录的update时间，如modified_time）

- 数据库日志中标示数据记录的更新时间的时间戳字段（如log_time）

- 数据库表中的用来记录具体业务过程的发生时间（如proc_time）

在实际的生产过程中，以上三个时间戳往往会存在差异：比如由于网络或者系统压力问题，log_time或者modified_time会晚于proc_time。

当时用数据库记录更新时间或者数据库日志更新时间进行切分数据分区时，有可能会导致凌晨时间产生的数据记录漂移到后一天，如果使用业务时间进行限制，则会遗漏很多其他过程的变化记录。

那么，该如何解决上述的问题呢？常见的方式有两种：

- 多冗余数据

基本原则是宁多勿少，即ODS每个时间分区中向前向后都多冗余一些数据，具体的数据切分让下游根据自身不同的业务场景根据不同的业务时间proc_time来限制。这种情况同样也会存在一些误差：比如一个订单是在6.1日支付的，但在6.2号凌晨申请退款关闭了该条订单，那该条订单记录就会被更新，下游再统计支付订单状态时会错误统计。

- 多个时间戳字段限制时间来获取相对准确的数据
- 首先确保数据不遗漏，根据log_time分别冗余前一天最后15分钟的数据和后一天凌晨开始15分钟的数据，并用modified_time过滤非当天数据，此时会过滤掉一部分后一天凌晨开始15分钟的数据，但是还是会冗余一部分前一天的数据，由于log数据保存了多个状态的数据，所以还需要根据log_time进行降序排列，获取最新状态的记录，这样就去掉了中间状态的数据。
- 下一步就是处理漂移到后一天的数据，根据log_time取后一天的15分钟数据；针对此数据，按照主键根据log_time作**升序**排列去重。因为我们需要获取的最接近当天记录变化情况（数据库日志数据将保留所有变化的数据，但是落地到ODS的表是需要根据主键去重获取最后状态的变化情况)，这样就会把漂移到后一天的最初状态的数据筛选出来了。
- 最后将前两步的结果数据作全外连接，限定业务时间proc_time来获取我们需要的数据

#### 4.2.3 数据存储

- 避免重复抽取数据，
  这种情况在中小公司基本上不会存在，但是在大型的集团公司，不同的数据团队负责不同的数据集市或者业务，会存在重复同步数据源的情况，解决这类问题的首要措施不是技术上而是管理上的，必须建立统一的ODS层，收拢权限，由专门的团队统一管控。

- 表的生命周期管理
  一般而言，全量表保存3~7天，增量表要永久保存

- 无下游任务的表
  比如一些表上源表不产生数据了，或者该表没有被下游任务使用，这种情况下要及时下线同步任务，避免造成资源的浪费

## 5 DWS设计概要