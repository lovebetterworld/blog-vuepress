---
title: Hive进阶手册
date: 2022-10-26 09:36:34
permalink: /bigdata/Hive02/
categories: 
  - Hive
tags: 
  - Hive
---

数据库和数仓区别

|                | DW                                                           | 数据库                                                       |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 用途           | 专门为数据分析设计的，涉及读取大量数据以了解数据之间的关系和趋势 | 用于捕获和存储数据                                           |
| 特性           | 数据仓库                                                     | 事务数据库                                                   |
| 适合的工作负载 | 分析、报告、大数据                                           | 事务处理                                                     |
| 数据源         | 从多个来源收集和标准化的数据                                 | 从单个来源（例如事务系统）捕获的数据                         |
| 数据捕获       | 批量写入操作通过按照预定的批处理计划执行                     | 针对连续写入操作进行了优化，因为新数据能够最大程度地提高事务吞吐量 |
| 数据标准化     | 非标准化schema，例如星型Schema或雪花型schema                 | 高度标准化的静态schema                                       |
| 数据存储       | 使用列式存储进行了优化，可实现轻松访问和高速查询性能         | 针对在单行型物理块中执行高吞吐量写入操作进行了优化           |
| 数据访问       | 为最小化I/O并最大化数据吞吐量进行了优化                      | 大量小型读取操作                                             |

## 1 Hive中的数据分层

- [Hive中的ODS、 DWD、 DWS、 ADS 数仓分层](https://www.cnblogs.com/zyp0519/p/15353930.html)

数仓-ODS层：

1）保持数据原貌不做任何修改，起到备份数据的作用。

2）数据采用LZO压缩，减少磁盘存储空间。100G数据可以压缩到10G以内。

3）创建分区表，防止后续的全表扫描，在企业开发中大量使用分区表。

4）创建外部表。在企业开发中，除了自己用的临时表，创建内部表外，绝大多数场景都是创建外部表。

理论上一般分为三个层：**ODS数据运营层、DW数据仓库层、ADS数据服务层**。基于这个基础分层之上，再提交信息的层次，来满足不同的业务需求。

1. 原始数据拉取过来，保持和元数据同步，不做处理形成ODS层；

2. 基于ODS层，保持数据原始粒度，对数据加工和处理（也就是清洗），提供干净的数据作DWD层；

3. 根据ODS和DWD层数据，进行轻度汇总，保留较多维度，形成DWM层；

4. 基于以上所有DW层数据，进行高度汇总，形成DWS层。

### 1.1 数据运营层（ODS）:原始数据

ODS：Operation Data Store 数据准备区，也称为**贴源层**。数据仓库源头系统的数据表通常会**原封不动**的存储一份，称为ODS层，是后续数据仓库加工数据的来源。

ODS层数据的来源方式：

1. 业务库 : 经常会使用sqoop来抽取，例如每天定时抽取一次。实时方面，可以考虑用canal监听mysql的binlog，实时接入即可。
2. 埋点日志 : 日志一般以文件的形式保存，可以选择用flume定时同步。可以用spark streaming或者Flink来实时接入
3. 消息队列：即来自ActiveMQ、Kafka的数据等。

### 1.2 数据仓库层（DW）：数据清洗,建模

**DW数据分层，由下到上为DWD（数据明细层），DWM（数据中间层），DWS（数据服务层）。从 ODS 层中获得的数据按照主题建立各种数据模型。这一层和维度建模会有比较深的联系。**

1> DWD：data warehouse details 细节数据层，是业务层与数据仓库的隔离层。主要对ODS数据层做一些数据清洗和规范化的操作。（依企业业务需求）数据清洗：去除空值、脏数据、超过极限范围的。

这一层主要是保证数据的质量和完整，方便后续层中特征分析

2> DWM：也有的称为DWB（data warehouse base） 数据基础层，对数据进行轻度聚合，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。

这里最容易搞混，实际生产中甚至跳过这个，只有dwd和dws层，其实严格要求上来讲，dwd层数据来源于生产系统，只对数据负责，别的不考虑。而到了dwm层，已经开始向我们的业务层靠拢，要根据数据来进行分析和轻度聚合，进行细粒度统计和沉淀。

3> DWS：data warehouse service 数据服务层，基于DWB上的基础数据，整合汇总成分析某一个主题域的服务数据层，一般是宽表。按照业务进行划分：流量、用户、订单....用于提供后续的业务查询，OLAP分析，数据分发等。

在这一层我们还会建立维度模型，常见的有雪花模型和星型模型。维度建模一般按照以下四个步骤：

1. 选择业务过程 2. 声明粒度 3. 确定维度 4. 确定事实。

这一层主要对ODS/DWD层数据做一些汇总。我们希望80%的业务都能通过我们的DWS层计算，而不是ODS。

### 1.3 数据服务层/应用层（ADS）：出报表

ADS：applicationData Service应用数据服务，该层主要是提供数据产品和数据分析使用的数据，一般会存储在ES、mysql等系统中供线上系统使用。

我们通过说的报表数据，或者说那种大宽表，一般就放在这里。

## 2 Hive数据压缩

- [【Hive】建表时的存储格式](https://blog.csdn.net/hyj_king/article/details/126776080)

Hive 在处理数据时，一般都需要经历文件读取和文件写出的过程，如果按照原文件的大小进行读写和传输，不仅效率查而且带宽的占用也很高，此时就需要我们这里所讲的 `存储格式` 和 `压缩算法`

### 2.1 不同的存储格式+压缩算法性能比较

文件存储格式不同对应不同的压缩算法，从而带来不同的性能，我们根据实际使用考虑压缩算法的性能，主要通过以下 3 个指标：

**① 压缩比**

压缩比越高，压缩后文件越小，所以压缩比越高越好；

压缩比越高，存储磁盘空间占用越小，可以降低单节点的磁盘IO，同时可以减少占用的带宽；

**② 压缩时间**

越快越好，加快数据在Hadoop集群流动的速度和磁盘 `IO` 的速度

**③ 压缩后的文件是否可以再分割**

可以分割的格式允许单一文件由多个Mapper程序处理，可以更好的并行化

| 压缩方式 | 压缩比 | 压缩速度 | 解压缩速度 | 是否可分割 |
| -------- | ------ | -------- | ---------- | ---------- |
| gzip     | 13.4%  | 21 MB/s  | 118 MB/s   | 否         |
| bzip2    | 13.2%  | 2.4MB/s  | 9.5MB/s    | 是         |
| lzo      | 20.5%  | 135 MB/s | 410 MB/s   | 是         |
| snappy   | 22.2%  | 172 MB/s | 409 MB/s   | 否         |

### 2.2 HIVE 中常用的存储格式对比

| 存储格式                  | 是否默认 | 存储方式                     | 压缩算法                            |
| ------------------------- | -------- | ---------------------------- | ----------------------------------- |
| TextFile                  | 是       | 行式存储                     | Gzip、Bzip2                         |
| SequenceFile              | 否       | 行式存储                     | NONE、RECORD、BLOCK                 |
| Parquet                   | 否       | 列式存储                     | Uncompress(默认)、Snappy、Gzip、Lzo |
| RCFile                    | 否       | 数据按行分块，每块按列存储   | -                                   |
| ORCFile(RCFile的进化版本) | 否       | 数据按行分块，每块按照列存储 | NONE、ZLIB(默认)、SNAPPY            |

| 存储方式 | 行查询效率 | 列查询效率 | 压缩效率 |
| -------- | ---------- | ---------- | -------- |
| 行式存储 | 高         | 低         | 低       |
| 列式存储 | 低         | 高         | 高       |

### 2.3 TEXTFILE

HIVE 中默认的存储格式；

一般使用在数据贴源层(ODS 或 STG) ，针对需要使用脚本 LOAD 加载数据到 HIVE 数仓表中的情况；

数据存储时不压缩，因此磁盘的开销和数据解析开销比较大；

TEXTFILE 可以结合 Gzip、Bzip2 等压缩算法使用(系统自动检查，执行查询时自动解压)，但使用这种方式，HIVE 不会对数据进行切分，从而无法对数据进行并行操作；

在反序列化过程中，必须逐个字符判断是不是分隔符和行结束符，因此反序列化开销会比 `SequenceFile` 高几十倍；

可以直接通过 `LOAD` 的方式从文件中加载数据到 `HIVE` 表中；

```sql
--- 可以不指定存储格式,默认使用 TEXTFILE
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识',
   user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
STORED AS TEXTFILE
PARTITIONED BY(ds string COMMENT '按交易日分区')
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
```

当用户的数据文件格式不能被当前 `HIVE` 所识别的时候，可以自定义文件格式

通过实现 `inputformat` 和 `outputformat` 来自定义输入输出格式

```sql
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识',
   user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
STORED AS 
INPUTFORMAT  'org.apache.hadoop.mapred.TextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat'
PARTITIONED BY(ds string COMMENT '按交易日分区')
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
```

### 2.4 SEQUENCE FILE

HADOOP API 提供的一种二进制文件，以 `key-value` 的形式序列化到文件中；

支持切片；

数据加载导入方式可以通过INSERT方式加载数据；

```sql
--- 可以不指定存储格式,默认使用 TEXTFILE
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
STORED AS SEQUENCEFILE
PARTITIONED BY(ds string COMMENT '按交易日分区')
;

CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
STORED AS 
STORED AS 
INPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileOutputFormat'
```

### 2.5 PARQUET

面向列的二进制文件格式，所以是不可以直接读取的；

文件中包括该文件的数据和元数据，因此 `Parquet` 格式文件是自解析的；

使用场景在 `Impala` 和 `Hive` 共享数据和元数据的场景；

```sql
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
STORED AS PARQUET
-- 也可以使用
-- STORED AS PARQUETFILE
PARTITIONED BY(ds string COMMENT '按交易日分区')
;
1234567891011
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe'
STORED AS 
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'
```

### 2.6 ORCFILE

运用 `ORC` 可以提高 `HIVE` 的读、写、计算的性能，主要使用在 `DWD、DWB、DWS` 层

- 数据按行分块，每块按照列存储；

- 压缩快、快速列存取；

效率比 `rcfile` 高，是 `rcfile` 的改良版本；

不考虑 `ORC` 的场景：需要通过 `LOAD` 方式加载数据到表里；需要把表里数据导出或直接可以查看等场景，这两种场景更适合使用 `TEXTFILE` ，易读性要比 `ORC` 高很多；

ORC 文件格式可以使用 HIVE 自带的命令 `concatenate` 快速合并小文件

```sql
CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
-- 也可以使用 STORED AS ORCFILE
-- 指定压缩算法
STORED AS ORC TBLPROPERTIES ("orc.compress"="SNAPPY");
PARTITIONED BY(ds string COMMENT '按交易日分区')
;


CREATE TABLE CUST_INFO
(
   user_id    string   COMMENT '用户唯一标识'
  ,user_name  string   COMMENT '用户姓名'
)
COMMENT '用户信息明细表'
ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde'
STORED AS 
INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'
PARTITIONED BY(ds string COMMENT '按交易日分区')
;
```

### 2.7 使用总结

```bash
# 压缩比比较
ORC>  PARQUET > TEXTFILE
# 查询速度
ORC >  TEXTFILE > PARQUET
# 存储格式为ORC,不同的压缩算法比较压缩后的文件大小
ZLIB < SNAPPY < 非压缩
```

① 数据量较大

如果单个文件比较大，可以使用 `Parquet` 存储，`lzo` 压缩，可以避免由于读取不可分割大文件引发的数据倾斜

② 计算逻辑比较少

使用 `ORC` 存储 + `ZLIB` 压缩，可以尽量减少占用存储空间

③ 计算逻辑比较多

使用 `ORC` 存储 + `SNAPPY` 压缩，可以提高读写速度，从而提高整体计算性能

## 3 Hive分区表

- [大数据之hive（数据仓库工具）的分组和分区操作](https://blog.csdn.net/a18379692263/article/details/123170951)
- [Hive分区](https://blog.csdn.net/hyj_king/article/details/104966045)
- [Hive分区表详细介绍](https://juejin.cn/post/7040689938521653285#heading-13)

分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。

### 3.1 Hive分区概述

#### 3.1.1 Hive分区背景

在Hive Select查询中一般会扫描整个表内容，会消耗很多时间做没必要的工作。有时候只需要扫描表中关心的一部分数据，因此建表时引入了partition概念。

#### 3.1.2 Hive分区实质

因为Hive实际是存储在HDFS上的抽象，Hive的一个分区名对应hdfs的一个目录名，并不是一个实际字段。

#### 3.1.3 Hive分区的意义

辅助查询，缩小查询范围，加快数据的检索速度和对数据按照一定的规格和条件进行管理。

#### 3.1.4 常见的分区技术

hive表中的数据一般按照时间、地域、类别等维度进行分区。

### 3.2 分区操作

#### 3.2.1 静态分区

##### 3.2.1.1 单分区

**(1)创建表**

```sql
hive> create table student(id string,name string) partitioned by(classRoom string) row format delimited fields terminated by ',';
OK
Time taken: 0.259 seconds
```

注意：partitioned by()要放在row format...的前面；partitioned by()里面的分区字段不能和表中的字段重复，否则报错；

**(2)加载数据**

```sql
hive> load data local inpath '/home/test/stu.txt' into table student partition(classroom='002');
Loading data to table default.student partition (classroom=002)
OK
```

**(3)查看分区**

```sql
hive> show partitions student;
OK
classroom=002
Time taken: 0.071 seconds, Fetched: 1 row(s)
```

##### 3.2.1.2 多分区

**(1)创建表**

```sql
hive> create table stu(id string,name string) partitioned by(school string,classRoom string) row format delimited fields terminated by ',';
OK
Time taken: 0.074 seconds
hive> desc stu;
OK
id                  	string              	                    
name                	string              	                    
school              	string              	                    
classroom           	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
	 	 
school              	string              	                    
classroom           	string              	                    
Time taken: 0.03 seconds, Fetched: 10 row(s)
```

**(2)加载数据**

```sql
hive> load  data local inpath '/home/test/stu.txt' into table stu partition(school='AA',classroom='005');
Loading data to table default.stu partition (school=AA, classroom=005)
OK
Time taken: 0.779 seconds
hive> select * from stu;
OK
001	xiaohong	AA	005
002	xiaolan	AA	005
Time taken: 0.087 seconds, Fetched: 2 row(s)
```

**(3)查看分区**

```sql
hive> show partitions stu;
OK
school=AA/classroom=005
Time taken: 0.048 seconds, Fetched: 1 row(s)
```

注意：这是个嵌套目录；

#### 3.2.2 动态分区

静态分区与动态分区的主要区别在于静态分区是手动指定，而动态分区是通过数据来进行判断。详细来说，静态分区的列实在编译时期，通过用户传递来决定的；动态分区只有在SQL执行时才能决定。

##### 3.2.2.1 启用hive动态分区

在hive会话中设置两个参数：

```
hive> set hive.exec.dynamic.partition=true;
hive> set hive.exec.dynamic.partition.mode=nonstrict;
```

##### 3.2.2.2 创建表

**(1)首先准备一个带有静态分区的表**

```sql
hive> select * from stu;
OK
001	xiaohong	AA	001
002	xiaolan	AA	001
001	xiaohong	AA	005
002	xiaolan	AA	005
001	xiaohong	BB	001
002	xiaolan	BB	001
Time taken: 0.105 seconds, Fetched: 6 row(s)
```

**(2)copy一张表结构相同的表**

```sql
hive> create table stu01 like stu;
OK
Time taken: 0.068 seconds
hive> desc stu;
OK
id                  	string              	                    
name                	string              	                    
school              	string              	                    
classroom           	string              	                    
	 	 
# Partition Information	 	 
# col_name            	data_type           	comment             
	 	 
school              	string              	                    
classroom           	string              	                    
Time taken: 0.022 seconds, Fetched: 10 row(s)
```

**(3)加载数据，分区成功**

不指定具体的学校和班级，让系统自动分配；

```sql
hive> insert overwrite table stu01 partition(school,classroom) 
    > select * from stu;
hive> select * from stu;
OK
001	xiaohong	AA	001
002	xiaolan	AA	001
001	xiaohong	AA	005
002	xiaolan	AA	005
001	xiaohong	BB	001
002	xiaolan	BB	001
Time taken: 0.091 seconds, Fetched: 6 row(s)
hive> select * from stu01;
OK
001	xiaohong	AA	001
002	xiaolan	AA	001
001	xiaohong	AA	005
002	xiaolan	AA	005
001	xiaohong	BB	001
002	xiaolan	BB	001
Time taken: 0.081 seconds, Fetched: 6 row(s)
```

### 3.3 分区表基本操作

1）创建分区表

```sql
create table dept_par(deptno int,dname string,loc string) partitioned by(day string)
row format delimited fields terminated by '\t';
```

 注：分区表设置的分区字段要区别于表中字段

 2）加载数据到分区表（数据准备，在本地创建文件数据）

```bash
dept_20220225.txt
10 ACCOUNTING 1700
20 RESEARCH 1800

dept_20220226.txt
30 SALES 1900
40 OPERATIONS 1700

dept_20220227.txt
50 TEST 2000
60 DEV 1900
```

加载数据到具体的分区

```sql
load data inpath '/opt/module/hive/data/dept_20220225.txt' into table dept_par partition(day='20220225');
load data inpath '/opt/module/hive/data/dept_20220226.txt' into table dept_par partition(day='20220226');
load data inpath '/opt/module/hive/data/dept_20220227.txt' into table dept_par partition(day='20220227');
```

 即可在hdfs集群上查看加载的分区数据

 3）分区表数据查询

```sql
单分区数据查询
 select * from dept_partition where day='20220225';
多分区数据查询
 select * from dept_partition where day='20220225'
 union
 select * from dept_partition where day='20220226'
 union
 select * from dept_partition where day='20220227';
```

4） 增加分区

```sql
alter table dept_par add partition(day='20220228');
创建多个分区
alter table dept_partition add partition(day='20220224') ,partition(day='20220223');
```

5）删除分区

```sql
alter table dept_partition drop partition (day='20220224');
同时删除多个分区
alter table dept_partition drop partition (day='20220223'), partition(day='20220228');
注：删除和增加分区以逗号区分
```

6）查看分区表信息

```sql
分区表结构
desc formatted dept_partition;
查看多少个分区
show partitions dept_partition;
```

### 3.4 二级分区

如果一天的数据量也很大的情况下，就要在每天下面在对每个小时的数据进行分区

1）创建二级分区

```sql
create table dept_partition2(
 deptno int, dname string, loc string
 )
 partitioned by (day string, hour string)
 row format delimited fields terminated by '\t';
```

2）加载数据

```sql
load data local inpath 
'/opt/module/hive/datas/dept_20220225.txt' into table
dept_partition2 partition(day='20220225', hour='12');
```

3）查看分区数据

```sql
select * from dept_partition2 where day='20220225' and hour='12';
```

### 3.5 动态分区调整（即分区的数据按照表字段来分区）

关系型数据库中，对分区表 Insert 数据时候，数据库自动会根据分区字段的值，将数据 插入到相应的分区中，Hive 中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过， 使用 Hive 的动态分区，需要进行相应的配置。

1）设置为非严格模式（动态分区的模式，默认 strict，表示必须指定至少一个分区为 静态分区，nonstrict 模式表示允许所有的分区字段都可以使用动态分区。）

```delphi
set hive.exec.dynamic.partition.mode=nonstrict
```

 例如：：将 dept 表中的数据按照地区（loc 字段），插入到目标表 dept_partition 的相应分区中。

创建目标分区表

```sql
create table dept_par4(id int, name string) 
partitioned by (loc int) row format delimited fields terminated by '\t';
```

 设置动态分区

```sql
insert into table dept_par4 partition(loc) select deptno, dname, loc from dept;
```

注：查询语句的最后字段默认为分区字段。

## 4 分桶表

分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分。

分桶是将数据集分解成更容易管理的若干部分的另一个技术。

分区针对的是数据的存储路径；分桶针对的是数据文件。

1）创建分桶表

```sql
create table stu_buck(id int, name string)
clustered by(id) 
into 4 buckets
row format delimited fields terminated by '\t';
```

2）导入数据（hdfs上的数据）

```sql
load data inpath '/student.txt' into table stu_buck;
```

注：Hive 的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中。

### 4.1 抽样查询

对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive 可以通过对表进行抽样来满足这个需求。

语法: TABLESAMPLE(BUCKET x OUT OF y)（注意：x 的值必须小于等于 y 的值）

查询表 stu_buck 中的数据（从第一个桶开始到第四个桶（4表示将全部数据随机分为四份），随机抽取一个桶的数据）。

```csharp
select * from stu_buck tablesample(bucket 1 out of 4 on id);
```

