---
title: 02.Prometheus
date: 2022-10-21 09:37:34
permalink: /devops/prometheus01/
categories: 
  - Prometheus
tags: 
  - Prometheus
---

> 运维监控平台设计思路
>
> 1. 数据收集模块
> 2. 数据提取模块
> 3. 监控告警模块

## 1 Prometheus 的监控体系

- [Prometheus 监控详解_公博义的博客-CSDN博客_prometheus监控](https://blog.csdn.net/shenyuanhaojie/article/details/121775976)
- [Prometheus 监控服务 抓取配置说明-接入指南-文档中心-腾讯云 (tencent.com)](https://cloud.tencent.com/document/product/1416/55995)

**`系统层监控（需要监控的数据）`**

1. CPU、Load、Memory、swap、disk i/o、process 等
2. 网络监控：网络设备、工作负载、网络延迟、丢包率等

**`中间件及基础设施类监控`**

1. 消息中间件：kafka、redis、RocketMQ 等消息代理/中间件
2. WEB 服务器容器：tomcat、weblogic、apache、php、spring 系列
3. 数据库/缓存数据库：MySQL、PostgreSQL、MogoDB、es、redis

redis 监控内容：

- redis 所在服务器的系统层监控
- redis 服务状态
- RDB AOF 日志监控
  (日志 -》如果是哨兵模式 -》哨兵共享集群信息，产生的日志 -》直接包含的其他节点哨兵信息及 mysql 信息)
- key 的数量
- key 被命中的数据/次数
- 最大连接数 -》redis 和系统
  (系统：ulimit -a。redis：redis-cli 登陆 -》config get maxclients 查看最大连接。)

**`应用层监控`**

**用于衡量应用程序代码状态和性能**

1. 白盒监控：自省指标，等待被下载
2. 黑盒监控：基于探针的监控方式，不会主动干预、影响数据

**`业务层监控`**

**用于衡量应用程序的价值**

1. 如电商业务的销售量，QPS、dau 日活、转化率等。
2. 业务接口：登入数量，注册数、订单量、搜索量和支付量。

### 1.1 Prometheus 时序数据

  时序数据，是在一段时间内通过重复测量（measurement）而获得的观测值的集合将这些观测值绘制于图形之上，它会有一个数据轴和一个时间轴，服务器指标数据、应用程序性能监控数据、网络数据等也都是时序数据。

- 数据来源：

  prometheus 基于 HTTP call (http/https 请求），从配置文件中指定的网络端点 `endpoint/IP:端口` 上周期性获取指标数据。很多环境、被监控对象，本身是没有直接响应/处理 http 请求的功能，prometheus-exporter 则可以在被监控端收集所需的数据，收集过来之后，还会做标准化，把这些数据转化为 prometheus 可识别，可使用的数据。

- 收集数据：

监控概念：白盒监控、黑盒监控

白盒监控：自省方式，被监控端内部，可以自己生成指标，只要等待监控系统来采集时提供出去即可。

黑盒监控：对于被监控系统没有侵入性，对其没有直接 “影响”，这种类似于基于探针机制进行监控（snmp 协议）。

`Prometheus 支持通过三种类型的途径从目标上 "抓取（Scrape)" 指标数据（基于白盒监控）`

```bash
Exporters -> 工作在被监控端，周期性的抓取数据并转换为 pro 兼容格式等待 prometheus 来收集，自己并不推送。
Instrumentation -> 指被监控对象内部自身有数据收集、监控的功能，只需要 prometheus 直接去获取。
Pushgateway -> 短周期 5s-10s 的数据收集。
```

- 获取方式：

**Prometheus 同其它 TSDB 相比有一个非常典型的特性，它主动从各 Target 上拉取数据，而非等待被监控端的推迭。(pull/push)**

**`两个获取方式各有优劣，其中，Pull 模型的优势在于：`**
集中控制：有利于将配置集在 Prometheus server 上完成，包括指标及采取速率等。Prometheus 的根本目标在于收集在 target 上预先完成聚合的聚合型数据，而非一款由事件驱动的存储系统通过 targets（标识的是具体的被监控端）。

```
比如配置文件中的 targets:['localhost:9090']
```

### 1.2 Prometheus 生态组件

```
prometheus 生态圈中包含了多个组件，其中部分组件可选。
```

- Prometheus server：收集和储存时间序列数据。通过 scraping 以刮擦的方式去获取数据放入 storge（TSDB 时序数据库），制定 Rules/Alerts 告警规则，service discovery 自动发现需要监控的节点。
- Client Library：客户端库，目的在于为那些期望原生提供 Instrumentation 功能的应用程序提供便捷的开发途径。
- Push Gateway：接收那些通常由短期作业生成的指标数据的网关，并支持由 Prometheus Server 进行指标拉取操作。
- Exporters：用于暴露现有应用程序或服务（不支持 Instrumentation）的指标给 Prometheus server。

> 而 pro 内建了数据样本采集器，可以通过配置文件定义，告诉 prometheus 到那个监控对象中采集指标数据，prometheus 采集过后，会存储在自己内建的 TSDB 数据库中，提供了 PromQL 支持查询和过滤操作，同时支持自定义规则来作为告警规则，持续分析一场指标，一旦发生，通知给 alerter 来发送告警信息，还支持对接外置的 UI 工具( grafana）来展示数据。采集、抓取数据是其自身的功能，但一般被抓取的数据一般来自于：export/instrumentation (指标数据暴露器）来完成的，或者是应用程序自身内建的测量系统（汽车仪表盘之类的，测量、展示）。

- Alertmanager：prometheus 可以生成告警信息，但是不能直接提供告警，需要使用一个外置的组件 altermanager 来进行告警。由告警规则对接，从 Prometheus Server 接收到 “告警通知” 后，通过去重、分组、路由等预处理功能后高效向用户完成告警信息发送。emailetcd 优势在于 `收敛、支持静默、去重、可以防止告警信息的轰炸`。
- Data Visualization（Dashboards）：与 TSDB 对接并且展示数据库中的数据，Prometheus web UI（Prometheus Server 内建），及 Grafana 等。
- Service Discovery：动态发现待监控的 Target，从而完成监控配置的重要组件，在容器化环境中尤为有用。该组件目前由 PrometheusServer 内建支持。
- PromQL（告警规则编写)：通常告警规则的文件指定输出到展示界面（grafana)
- UI 表达式浏览器（调试）

### 1.3 Prometheus 数据模型

#### 1.3.1 概述

- Prometheus 仅用键值方式存储时序式的聚合数据，不支持文本信息
- 其中的 “键” 称为指标（metric），通常意味着 CPU 速率、内存使用率或分区空闲比例等
- 同一指标可能适配到多个目标或设备、因而它使用 “标签” 作为元数据，从而为 metric 添加更多的信息描述维度
- Prometheus 每一份样本数据都包含了：

```bash
① 时序列标识：key+lables
② 当前时间序列的样本值value
③ 这些标签可以作为过滤器进行指标过滤及聚合运算，如何从上万的数据过滤出关键有限的时间序列，同时从有限的时间序列在特定范围的样本那就需要手动编写出时间序列的样本表达式来过滤出我们想要的样本数据
```

#### 1.3.2 指标类型

```
默认都是双精度浮点型数据（服务器端无数据量类型数据）
```

- counter：计数器单调递增
- gauge：仪表盘:有起伏特征的
- histogram：直方图

>   在一段时间范围内对数据采样的相关结果，并记入配置的 bucket 中，它可以存储更多的数据，包括样本值分布在每个 bucket 的数量，从而 prometheus 就可以使用内置函数进行计算。
> 计算样本平均值：以值得综合除以值的数量
> 计算样本分位值：分位数有助于了解符合特定标准的数据个数，例如评估响应时间超过1秒的请求比例，若超过20侧则进行告警等

- summary：摘要，histogram 的扩展类型，它是直接由监控端自行聚合计算出分位数，同时将计算结果响应给 prometheus server 的样本采集请求，因而，其分位数计算是由监控端完成

#### 1.3.3 作业 job 和实列 targets/instance

- job：能够接收 prometheus server 数据 scrape ，如 `"mysql nodes" "mysql master slave"`
- targets：每一个可以被监控的系统，成为 targets 多个相同的 targets 的集合（类）称为 job
- instance：实例与 targets 类似。与 target 相比，instance 更趋近于一个具体可以提供监控数据的实例，而 targets 则更像一个对象、目标性质。

#### 1.3.4 PrometheusQL（数据查询语言也是时序数据库使用语言)

```
支持两种向量，同时内置提供了一组用于数据处理的函数
```

- 即时向量：最近以此时间戳上跟踪的数据指标，表示的是一个时间刻度
- 即时向量选择器：返回0个1个或者多个时间序列上在给定时间戳上的各自的一个样本，该样本成为即时样本
- 时间范围向量：指定时间范围内所有时间戳上的数据指标，表示的是一组时间区间
- 范围向量选择器：返回0个1个或多个时间序列上在给定时间范围内的各自的一组样本(范围向量选择器无法用于绘图)

## 2 Prometheus SpringBoot监控

- [prometheus自定义监控：监控接口的实时调用情况_ankora的博客-CSDN博客_prometheus 接口监控](https://blog.csdn.net/ankora/article/details/116600773)

### 2.1 SpringBoot集成Micrometer

> 需要注意Spring Boot 和 micrometer的版本号。不同的micrometer版本支持的Spring Boot 版本也不相同。

```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>

<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

这里引入了 io.micrometer 的 micrometer-registry-prometheus 依赖以及 spring-boot-starter-actuator 依赖，因为该包对 Prometheus 进行了封装，可以很方便的集成到 Spring Boot 工程中。

### 2.2 修改配置文件，打开Actuator监控端点

在 application.yml 中配置如下：

```yaml
spring:
  application:
    name: PrometheusApp

#Prometheus springboot监控配置
management:
  endpoints:
    web:
      exposure:
        include: '*'
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name} # 暴露的数据中添加application label
```

上面的配置中， include=* 配置为开启 Actuator 服务，Spring Boot Actuator 自带了一个/actuator/Prometheus 的监控端点供给Prometheus 抓取数据。不过默认该服务是关闭的，所以，使用该配置将打开所有的 Actuator 服务。

最后，启动服务，然后在浏览器访问 http://127.0.0.1:8080/actuator/prometheus ，就可以看到服务的一系列不同类型 metrics 信息，例如 http_server_requests_seconds summary、jvm_memory_used_bytes gauge、jvm_gc_memory_promoted_bytes_total counter 等等。

### 2.3 将应用添加到Prometheus

修改 Prometheus 的配置文件 prometheus.yml ，添加上边启动的服务地址来执行监控。

`vim /usr/local/etc/prometheus.yml` 。具体配置如下：

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "prometheus"
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
      - targets: ["localhost:9090"]

  # 采集node exporter监控数据
  - job_name: 'node'
    static_configs:
      - targets: ['10.2.1.231:9527']

  - job_name: 'prometheusapp'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['10.2.1.159:8080']
```

上面的prometheusapp 就是前面创建的Spring Boot 应用程序，也就是 Prometheus 需要监控的服务地址。

然后，重启 Prometheus 服务，查看 Prometheus UI 界面确认 Target 是否添加成功。

### 2.4 使用 Grafana Dashboard 展示应用数据

直接在[https://grafana.com/dashboards](https://grafana.com/dashboards?spm=a2c6h.12873639.article-detail.14.41f46fe3DKiyAm) 下载Spring Boot的模板（这里使用的是编号4701）。

## 3 自定义监控指标

- [彻底搞懂监控系统，使用Prometheus监控Spring Boot应用，自定义应用监控指标！-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/989594#slide-1)

Micrometer支持自定义监控指标，实现业务方面的数据监控。例如统计访问某一个 API 接口的请求数，统计实时在线人数、统计实时接口响应时间等。

接下来，我们以监控所有API请求次数为例，演示如何自定义监控指标并展示到Grafana 。

### 3.1 添加指标统计

首先，在之前的Spring Boot项目中，创建`CustomMetricsController` 控制器，具体示例代码如下：

```java
@RestController
@RequestMapping("/custom/metrics")
public class CustomMetricsController {

    @Autowired
    private MeterRegistry meterRegistry;

    /**
     * 订单请求测试
     */
    @GetMapping("/order/{appId}")
    public String orderTest(@PathVariable("appId") String appId) {
        Counter.builder("metrics.request.count").tags("apiCode", "order").register(meterRegistry).increment();
        return "order请求成功：" +appId ;
    }

    /**
     * 产品请求测试
     */
    @GetMapping("/product/{appId}")
    public String productTest(@PathVariable("appId") String appId) {
        Counter.builder("metrics.request.count").tags("apiCode", "product").register(meterRegistry).increment();
        return "product请求成功：" +appId ;
    }
}
```

如上所示，使用Counter 计数器定义了自定义指标参数：metrics_request_count，来统计相关接口的请求次数。这里只是测试，所以直接在Controller类中进行统计。

实际项目项目中，应该是使用AOP，或是拦截器的方式统计所有接口的请求信息，减少这种非关键代码的侵入性。

验证测试，重新启动Spring Boot 应用。分别访问：http://127.0.0.1:8080/custom/metrics/order/{http://10.2.1.159:8080/custom/metrics/order/{appId})和http://127.0.0.1:8080/custom/metrics/product/接口，然后在 Promtheus 中查看自定义的指标数据：`metrics_request_count_total`。

### 3.2 创建Grafana数据面板

在 Grafana Dashboard展示我们自定义的监控指标。其实也非常简单，创建一个新的数据面板Panel 并添加 Query 查询，相关的监控指标就图形化展示出来了。接下来演示在Grafana上创建数据面板。

首先，页面的右上角的Add panel | Add a new Panel，添加一个 Panel，并命名为：统计接口请求次数。可以选择选择想要展示的图形，如：连线图、柱状图等。

然后，在panel的下方增加 Query 查询，选择数据源为之前定义的Prometheus-1，指标选择之前自定义的指标数据：`metrics_request_count_total`，点击applay 保存之后，返回首页就可以看到刚添加的 panel。

如上图所示，上面我们新增加的panel中成功显示了我们自定义的监控数据。继续请求之前的应用接口，数据会正常刷新。说明Grafana上的指标数据展示配置成功。

## 4 Springboot开启prometheus监控指标获取HTTP请求的吞吐时延等

- [Springboot开启prometheus监控指标获取HTTP请求的吞吐时延等 - 许伟强 - 博客园 (cnblogs.com)](https://www.cnblogs.com/xuweiqiang/p/16451862.html)

在启动类注册：

```java
@SpringBootApplication
@ServletComponentScan
public class OneApplication {

    public static void main(String[] args) {
        SpringApplication.run(OneApplication.class, args);
    }

    // 非常重要
    @Bean
    MeterRegistryCustomizer<MeterRegistry> configurer(
            @Value("${spring.application.name}") String applicationName) {
        return (registry) -> registry.config().commonTags("application", "hello");
    }
}
```

在配置中添加

```
management.endpoints.web.exposure.include=*
management.metrics.tags.application="one"
management.metrics.web.server.request.metric-name = http.server.requests
```

### 4.1 特殊需求

- 自定义指标名称
- 如何给每一个请求打上自定义的tag
- 更改默认的标签tag的名称
- 有些status 200的日志，但是业务上是错误的，比如请求参数非法，如何埋点获取
- 配置grafana的图示呈现吞吐、错误分布、时延
- 获取网站在线人数

#### 4.1.1 添加自定义标签，给每个接口增加一个team标识

```java
import java.util.List;

import io.micrometer.core.annotation.Timed;

import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

@RestController
@Timed
public class MyController {

    @GetMapping("/api/addresses")
    public List<Address> listAddress() {
        return ...
    }

    @GetMapping("/api/people")
    @Timed(extraTags = { "team", "test" })
    @Timed(value = "all.people", longTask = true)
    public List<Person> listPeople() {
        return ...
    }

}
```

在 config 要添加以下

```
management.metrics.tags.team=""
```

## 5 Prometheus配置监控ip、端口连通，get、post接口连通和状态码

- [Prometheus配置监控ip、端口连通，get、post接口连通和状态码 - 简书 (jianshu.com)](https://www.jianshu.com/p/826f757b2b82)

### 5.1 prometheus.yml

```yaml
# 全局配置
global:
  # 默认拉取频率
  scrape_interval: 15s
  # 拉取超时时间
  scrape_timeout: 10s
  # 评估规则频率
  evaluation_interval: 15s

# 规则文件配置
rule_files: ['/etc/prometheus/rules/*.yml']

# 告警配置  
alerting:
  alertmanagers:
  - follow_redirects: true
    scheme: http
    timeout: 10s
    api_version: v2
    static_configs:
    - targets: []

# 拉取配置，添加监控项
scrape_configs:

# 监控prometheus
- job_name: prometheus
  metrics_path: /metrics
  static_configs:
  - targets:
    - localhost:9090

# 监控ip是否能ping通，docker启动的blackbox-exporter不建议用此监控，可能会有报错
- job_name: icmp_ping
  metrics_path: /probe
  params:
    module: [icmp]
  file_sd_configs:
  - files: ['/etc/prometheus/conf.d/icmp_ping/*.yml']
    refresh_interval: 10s
  relabel_configs:
  - source_labels: [__address__]
    regex: (.*)(:80)?
    target_label: __param_target
    replacement: ${1}
  - source_labels: [__param_target]
    target_label: instance
  - source_labels: [__param_target]
    regex: (.*)
    target_label: ping
    replacement: ${1}
  - source_labels: []
    regex: .*
    target_label: __address__
    replacement: 192.168.7.254:9115

# 监控端口是否能连通
- job_name: tcp_port
  metrics_path: /probe
  params:
    module: [tcp_connect]
  file_sd_configs:
  - files: ['/etc/prometheus/conf.d/tcp_port/*.yml']
    refresh_interval: 10s
  relabel_configs:
  - source_labels: [__address__]
    target_label: __param_target
  - source_labels: [__param_target]
    target_label: instance
  - target_label: __address__
    replacement: 192.168.7.254:9115 

# 监控get请求
- job_name: http_get
  metrics_path: /probe
  params:
    module: [http_2xx]
  file_sd_configs: 
  - files: ['/etc/prometheus/conf.d/http_get/*.yml']
    refresh_interval: 10s
  relabel_configs:
  - source_labels: [__address__]
    target_label: __param_target
  - source_labels: [__param_target]
    target_label: instance
  - target_label: __address__
    replacement: 192.168.7.254:9115

# 监控post请求
- job_name: http_post
  metrics_path: /probe
  params:
    module: [http_post_2xx]
  file_sd_configs: 
  - files: ['/etc/prometheus/conf.d/http_post/*.yml']
    refresh_interval: 10s
  relabel_configs:
  - source_labels: [__address__]
    target_label: __param_target
  - source_labels: [__param_target]
    target_label: instance
  - target_label: __address__
    replacement: 192.168.7.254:9115

# 监控post请求，有参数{"token":"prometheus_post_check_token"}
- job_name: http_post_with_token
  metrics_path: /probe
  params:
    module: [http_post_2xx_with_prometheus_post_check_token]
  file_sd_configs:
  - files: ['/etc/prometheus/conf.d/http_post_with_token/*.yml']
    refresh_interval: 10s
  relabel_configs:
  - source_labels: [__address__]
    target_label: __param_target
  - source_labels: [__param_target]
    target_label: instance
  - target_label: __address__
    replacement: 192.168.7.254:9115
```

### 5.2 rules.yml

```yaml
groups:
- name: probe_http_status_code
  rules:
  - alert: probe_http_status_code
    expr: probe_http_status_code != 200
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "{{ $labels.instance }}  状态码异常"
      description: "请尽快检测"
groups:
- name: probe_success
  rules:
  - alert: probe_success
    expr: probe_success == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "接口/主机/端口 {{ $labels.instance }}  无法联通"
      description: "请尽快检测"
```

### 5.3 blackbox.yml

```yaml
modules:
  http_2xx:
    prober: http
  http_post_2xx:
    prober: http
    http:
      method: POST
  tcp_connect:
    prober: tcp
  pop3s_banner:
    prober: tcp
    tcp:
      query_response:
      - expect: "^+OK"
      tls: true
      tls_config:
        insecure_skip_verify: false
  grpc:
    prober: grpc
    grpc:
      tls: true
      preferred_ip_protocol: "ip4"
  grpc_plain:
    prober: grpc
    grpc:
      tls: false
      service: "service1"
  ssh_banner:
    prober: tcp
    tcp:
      query_response:
      - expect: "^SSH-2.0-"
      - send: "SSH-2.0-blackbox-ssh-check"
  irc_banner:
    prober: tcp
    tcp:
      query_response:
      - send: "NICK prober"
      - send: "USER prober prober prober :prober"
      - expect: "PING :([^ ]+)"
        send: "PONG ${1}"
      - expect: "^:[^ ]+ 001"
  icmp:
    prober: icmp

  # 上面是自带的，下面是自定义的
  http_post_2xx_with_prometheus_post_check_token:
    prober: http
    http:
      method: POST
      headers:
        Content-Type: application/json   #添加头部
      body: '{"token":"prometheus_post_check_token"}'  #发送的相关数据
```

### 5.4 icmp_ping.yml

```yaml
- targets: ['192.168.7.254', '192.168.10.200']
  labels:
    group: 'ping监控'
```

### 5.5 tcp_port.yml

```yaml
- targets: ['192.168.7.254:8082', '192.168.7.254:8083']
  labels:
    group: '端口监控'
```

### 5.6 http_get.yml

```yaml
- targets:
  - http://192.168.7.254:8082/api/heartbeat/check/
  labels:
    name: 'get测试'

- targets:
  - http://192.168.7.254:8083/api/heartbeat/check_test/
  labels:
    name: 'get测试2'
```

### 5.7 http_post.yml

```yaml
- targets:
  - http://192.168.7.254:8082/api/heartbeat/post_check/
  labels:
    name: 'post测试'
```

### 5.8 http_post_with_token.yml

```yaml
- targets:
  - http://192.168.7.254:8082/api/heartbeat/post_check/
  labels:
    name: 'post带body测试'
```

## 6 部署 Service Discovery 服务发现

- [Prometheus 监控详解_公博义的博客-CSDN博客_prometheus监控](https://blog.csdn.net/shenyuanhaojie/article/details/121775976)

### 6.1 Prometheus 指标抓取的生命周期

```
发现 -> 配置 -> relabel -> 指标数据抓取 -> metrics relabel
```

Prometheus 的服务发现类型：

- 基于文件的服务发现
- 基于 DNS 的服务发现
- 基于 API 的服务发现：Kubernetes、Consul、Azure、重新标记；target 重新打标；metric 重新打标
- 基于 K8S 的服务发现

### 6.2 Prometheus 的服务发现机制

```
详细的 Prometheus 工作生命周期
```

- Prometheus Server 的数据抓取工作于 Pull 模型，因而它必需要事先知道各 Target 的位置，然后才能从相应的 Exporter 或 Instrumentation 中抓取数据。
- 对于小型的系统环境来说，通过 static_configs 指定各 Target 便能解决问题，这也是最简单的配置方法。每个 Targets 用一个网络端点 `ip:port` 进行标识。
- 对于中大型的系统环境或具有较强动态性的云计算环境来说，静态配置显然难以适用。
  因此，Prometheus 为此专门设计了一组服务发现机制，以便于能够基于服务注册中心（服务总线）自动发现、检测、分类可被监控的各 Target，以及更新发生了变动的 Target 指标抓取的生命周期。
- 在每个 scrape_interval 期间，Prometheus 都会检查执行的作业 Job，这些作业首先会根据 Job 上指定的发现配置生成 Target 列表，此即服务发现过程。服务发现会返回一个 Target 列表，其中包含一组称为元数据的标签，这些标签都以 `meta_` 为前缀。
- 服务发现还会根据目标配置来设置其它标签，这些标签带有 “” 前缀和后缀，包括 “scheme”、“address” 和 “metrics path_”，分别保存有 target 支持使用协议（http或https，默认为http) 、target 的地址及指标的 URI 路径（默认为 /metrics）。
- 若 URI 路径中存在任何参数，则它们的前缀会设置为 “param” 这些目标列表和标签会返回给 Prometheus，其中的一些标签也可以配置中被覆盖。
- 配置标签会在抓取的生命周期中被重复利用以生成其他标签，例如指标上的 instance 标签的默认值就来自于 address 标签的值。
- 对于发现的各目标，Prometheus 提供了可以重新标记（relabel）目标的机会，它定义在 job 配置段的 relabel_config 配置中。