---
title: 02.Java百万高并发的技术方案
date: 2022-09-13 09:51:00
permalink: /gbf/gbf02/
categories: 
  - 高并发
tags: 
  - 高并发
---

- [Java百万高并发的技术方案_Java后端何哥的博客-CSDN博客_百万并发架构](https://blog.csdn.net/CSDN2497242041/article/details/115608400)

# 一、什么是高并发

高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。

高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），每秒事务处理量TPS(Transaction Per Second)，并发用户数等。

**响应时间**：系统对请求做出响应的时间。

**吞吐量**：单位时间内处理的请求数量。

**QPS**：每秒响应查询请求数。

**TPS**：每秒响应事务请求数。

**并发用户数**：同时承载正常使用系统功能的用户数量。

## 1.1、如何理解高并发？

高并发意味着大流量，需要运用技术手段抵抗流量的冲击，这些手段好比操作流量，能让流量更平稳地被系统所处理，带给用户更好的体验。

我们常见的高并发场景有：淘宝的双11、春运时的抢票、微博大V的热点新闻等。除了这些典型事情，每秒几十万请求的秒杀系统、每天千万级的订单系统、每天亿级日活的信息流系统等，都可以归为高并发。

很显然，上面谈到的高并发场景，并发量各不相同，**那到底多大并发才算高并发呢？**

(1)不能只看数字，要看具体的业务场景。不能说10W QPS的秒杀是高并发，而1W QPS的信息流就不是高并发。信息流场景涉及复杂的推荐模型和各种人工策略，它的业务逻辑可能比秒杀场景复杂10倍不止。因此，不在同一个维度，没有任何比较意义。

(2)业务都是从0到1做起来的，并发量和QPS只是参考指标，最重要的是：在业务量逐渐变成原来的10倍、100倍的过程中，你是否用到了高并发的处理方法去演进你的系统，从架构设计、编码实现、甚至产品方案等维度去预防和解决高并发引起的问题？而不是一味的升级硬件、加机器做水平扩展。

此外，各个高并发场景的业务特点完全不同：有读多写少的信息流场景、有读多写多的交易场景，**那是否有通用的技术方案解决不同场景的高并发问题呢？**

我觉得大的思路可以借鉴，别人的方案也可以参考，但是真正落地过程中，细节上还会有无数的坑。另外，由于软硬件环境、技术栈、以及产品逻辑都没法做到完全一致，这些都会导致同样的业务场景，就算用相同的技术方案也会面临不同的问题，这些坑还得一个个趟。

因此，这篇文章会将重点放在基础知识和通用思路，希望让你对高并发有更深的理解。

## 1.2、 高并发系统设计的目标是什么？

先搞清楚高并发系统设计的目标，在此基础上再讨论设计方案和实践经验才有意义和针对性。

高并发绝不意味着只追求高性能，这是很多人片面的理解。从宏观角度看，高并发系统设计的目标有三个：高性能、高可用，以及高可扩展。

a、高性能：性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。

b、高可用：表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。

c、高扩展：表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。

![图片](https://img-blog.csdnimg.cn/img_convert/979b22a9f41ae156258049efb72469e1.png)

这3个目标是需要通盘考虑的，因为它们互相关联、甚至也会相互影响。

比如说：考虑系统的扩展能力，你会将服务设计成无状态的，这种集群设计保证了高扩展性，其实也间接提升了系统的性能和可用性。

再比如说：为了保证可用性，通常会对服务接口进行超时设置，以防大量线程阻塞在慢请求上造成系统雪崩，那超时时间设置成多少合理呢？一般，我们会参考依赖服务的性能表现进行设置。

------

# 二、提升系统的高并发能力

互联网分布式架构设计，提高系统高并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。

**（1）垂直扩展：**提升单机处理能力。垂直扩展的方式又有两种：

> 增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
>
> 提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；

因为单机性能总会存在极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力。

**（2）水平扩展：**只要增加服务器数量，就能[线性](https://so.csdn.net/so/search?q=线性&spm=1001.2101.3001.7020)扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计是本文重点讨论的内容。

做好分层架构，这是横向扩展的前提，因为高并发系统往往业务复杂，通过分层处理可以简化复杂问题，更容易做到横向扩展。

![图片](https://img-blog.csdnimg.cn/img_convert/d5db706c15b699d6e19728ae8d84c817.png)

上面这种图是互联网最常见的分层架构，当然真实的高并发系统架构会在此基础上进一步完善。比如会做动静分离并引入CDN，反向代理层可以是LVS+Nginx，Web层可以是统一的API网关，业务服务层可进一步按垂直业务做微服务化，存储层可以是各种异构数据库。

## 2.1、系统集群化部署+负载均衡

（1）添加负载均衡层，将请求均匀打到系统层。

（2）系统层采用集群化多活部署，扛住初步的并发压力。

## 2.2、读写分离+数据库分库分表+分布式数据库

（1）读写分离：主库写，从库读（数据同步延迟）。

（2）分库分表：水平拆分、垂直拆分（弊端太多如关联查询）。

（3）分布式数据库：TiDB（HTAP、兼任Mysql协议、水平扩展、分布式事务）

## 2.3、缓存

（1）本地缓存：本地磁盘或内存。

（2）分布式缓存：用缓存集群抗住大量的读请求。

（3）预缓存，多级缓存。

## 2.4、消息中间件

（1）系统解耦，数据同步。

（2）请求异步化处理，实现削峰填谷的效果。

## 2.5、应用拆分（微服务）

（1）按业务拆分、减少耦合。

（2）分级部署，扩容缩容。

（3）应用资源隔离。

## 2.6、CDN（内容分发网络）

（1）尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节, 使内容传输的更快更稳定。

（2）CDN能够实时地根据网络流量和各节点的链接，负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。

------

# 三、高并发具体的实践方案

针对高性能、高可用、高扩展3个方面，总结下可落地的实践方案。

**❇ 高性能的实践方案**

> 1、集群部署，通过负载均衡减轻单机压力。
>
> 2、多级缓存，包括静态数据使用CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点key、缓存穿透、缓存并发、数据一致性等问题的处理。
>
> 3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。
>
> 4、考虑NoSQL数据库的使用，比如HBase、TiDB等，但是团队必须熟悉这些组件，且有较强的运维能力。
>
> 5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。
>
> 6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx接入层的限流、服务端的限流。
>
> 7、对流量进行削峰填谷，通过MQ承接流量。
>
> 8、并发处理，通过多线程将串行逻辑并行化。
>
> 9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。
>
> 10、缓存预热，通过异步任务提前预热数据到本地缓存或者分布式缓存中。
>
> 11、减少IO次数，比如数据库和缓存的批量读写、RPC的批量接口支持、或者通过冗余数据的方式干掉RPC调用。
>
> 12、减少IO时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存key的大小、压缩缓存value等。
>
> 13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For循环的计算逻辑优化，或者采用更高效的算法。
>
> 14、各种池化技术的使用和池大小的设置，包括HTTP请求池、线程池（考虑CPU密集型还是IO密集型设置核心参数）、数据库和Redis连接池等。
>
> 15、JVM优化，包括新生代和老年代的大小、GC算法的选择等，尽可能减少GC频率和耗时。
>
> 16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。

上述方案无外乎从计算和 IO 两个维度考虑所有可能的优化点，需要有配套的监控系统实时了解当前的性能表现，并支撑你进行性能瓶颈分析，然后再遵循二八原则，抓主要矛盾进行优化。

**❇ 高可用的实践方案**

> 1、对等节点的故障转移，Nginx和服务治理框架均支持一个节点失败后访问另一个节点。
>
> 2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如redis的哨兵模式或者集群模式、MySQL的主从切换等）。
>
> 3、接口层面的超时设置、重试策略和幂等设计。
>
> 4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。
>
> 5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。
>
> 6、MQ场景的消息可靠性保证，包括producer端的重试机制、broker侧的持久化、consumer端的ack机制等。
>
> 7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。
>
> 8、监控报警：全方位的监控体系，包括最基础的CPU、内存、磁盘、网络的监控，以及Web服务器、JVM、数据库、各类中间件的监控和业务指标的监控。
>
> 9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。

高可用的方案主要从冗余、取舍、系统运维3个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。

**❇ 高扩展的实践方案**

> 1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。
>
> 2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。
>
> 3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求源拆（比如To C和To B，APP和H5）。

------

# 四、支持高并发的典型架构

我们看一下一个大概的支持高并发的典型架构：

![高并发典型架构](https://img-blog.csdnimg.cn/img_convert/66ae5b094dce8dfa1b2ca1f40af4d042.png)