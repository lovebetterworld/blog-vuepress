---
title: 01.高并发架构泛谈
date: 2022-06-29 14:51:00
permalink: /gbf/gbf01/
categories: 
  - 高并发
tags: 
  - 高并发
---

> 来源知乎：[我没有高并发项目经验，但是面试的时候经常被问到高并发、性能调优方面的问题，有什么办法可以解决吗？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/421237964/answer/2539314431)
>
> 部分优质内容记录。

## 1 Lowry

首先说一下，当我作为面试官问候选人**「对于高并发的理解」**时，我觉得**「答得不好」**的情况分成以下几类：

**1、对数据化的指标没有概念**：不清楚选择什么样的指标来衡量高并发系统？分不清并发量和QPS，不知道自己系统的总用户量、活跃用户量，平峰和高峰时的QPS和TPS等关键数据。

**2、设计过一些高并发方案，但是细节掌握不透彻**：讲不出该方案要关注的技术点和可能带来的副作用。比如读性能有瓶颈会引入缓存，但是忽视了缓存命中率、热点key、数据一致性等问题。

**3、理解片面，把高并发设计等同于性能优化**：大谈并发编程、多级缓存、异步化、水平扩容，却忽视高可用设计、服务治理和运维保障。

**4、掌握大方案，却忽视最基本的东西**：能讲清楚垂直分层、水平分区、缓存等大思路，却没意识去分析数据结构是否合理，算法是否高效，没想过从最根本的IO和计算两个维度去做细节优化。

下面，我再结合我的高并发项目经验，系统性地总结下高并发需要掌握的知识和实践思路，内容分成以下3个部分：

- 如何理解高并发？
- 高并发系统设计的目标是什么？
- 高并发的实践方案有哪些？

### **01 如何理解高并发？**

高并发意味着大流量，需要运用技术手段抵抗流量的冲击，这些手段好比操作流量，能让流量更平稳地被系统所处理，带给用户更好的体验。

我们常见的高并发场景有：淘宝的双11、春运时的抢票、微博大V的热点新闻等。除了这些典型事情，每秒几十万请求的秒杀系统、每天千万级的订单系统、每天亿级日活的信息流系统等，都可以归为高并发。

很显然，上面谈到的高并发场景，并发量各不相同，**那到底多大并发才算高并发呢？**

1、不能只看数字，要看具体的业务场景。不能说10W QPS的秒杀是高并发，而1W QPS的信息流就不是高并发。信息流场景涉及复杂的推荐模型和各种人工策略，它的业务逻辑可能比秒杀场景复杂10倍不止。因此，不在同一个维度，没有任何比较意义。

2、业务都是从0到1做起来的，并发量和QPS只是参考指标，最重要的是：在业务量逐渐变成原来的10倍、100倍的过程中，你是否用到了高并发的处理方法去演进你的系统，从架构设计、编码实现、甚至产品方案等维度去预防和解决高并发引起的问题？而不是一味的升级硬件、加机器做水平扩展。

此外，各个高并发场景的业务特点完全不同：有读多写少的信息流场景、有读多写多的交易场景，**那是否有通用的技术方案解决不同场景的高并发问题呢？**

我觉得大的思路可以借鉴，别人的方案也可以参考，但是真正落地过程中，细节上还会有无数的坑。另外，由于软硬件环境、技术栈、以及产品逻辑都没法做到完全一致，这些都会导致同样的业务场景，就算用相同的技术方案也会面临不同的问题，这些坑还得一个个趟。

因此，这篇文章我会将重点放在基础知识、通用思路、和我曾经实践过的有效经验上，希望让你对高并发有更深的理解。

### 02 高并发系统设计的目标是什么？

先搞清楚高并发系统设计的目标，在此基础上再讨论设计方案和实践经验才有意义和针对性。

#### **2.1 宏观目标**

高并发绝不意味着只追求高性能，这是很多人片面的理解。从宏观角度看，高并发系统设计的目标有三个：高性能、高可用，以及高可扩展。

1、高性能：性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。

2、高可用：表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。

3、高扩展：表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。

![img](https://pica.zhimg.com/80/v2-c8d4554b46d91bfa6466ffb4ae575b7f_720w.jpg?source=1940ef5c)

这3个目标是需要通盘考虑的，因为它们互相关联、甚至也会相互影响。

比如说：考虑系统的扩展能力，你会将服务设计成无状态的，这种集群设计保证了高扩展性，其实也间接提升了系统的性能和可用性。

再比如说：为了保证可用性，通常会对服务接口进行超时设置，以防大量线程阻塞在慢请求上造成系统雪崩，那超时时间设置成多少合理呢？一般，我们会参考依赖服务的性能表现进行设置。

#### **2.2 微观目标**

再从微观角度来看，高性能、高可用和高扩展又有哪些具体的指标来衡量？为什么会选择这些指标呢？

##### 2.2.1 [性能指标

通过性能指标可以度量目前存在的性能问题，同时作为性能优化的评估依据。一般来说，会采用一段时间内的接口响应时间作为指标。

1、平均响应时间：最常用，但是缺陷很明显，对于慢请求不敏感。比如1万次请求，其中9900次是1ms，100次是100ms，则平均响应时间为1.99ms，虽然平均耗时仅增加了0.99ms，但是1%请求的响应时间已经增加了100倍。

2、TP90、TP99等分位值：将响应时间按照从小到大排序，TP90表示排在第90分位的响应时间， 分位值越大，对慢请求越敏感。

![img](https://pic3.zhimg.com/80/v2-e68e5f8883886d72e2cb6a8d8d6026e8_720w.jpg?source=1940ef5c)

3、吞吐量：和响应时间呈反比，比如响应时间是1ms，则吞吐量为每秒1000次。

通常，设定性能目标时会兼顾吞吐量和响应时间，比如这样表述：在每秒1万次请求下，AVG控制在50ms以下，TP99控制在100ms以下。对于高并发系统，AVG和TP分位值必须同时要考虑。

另外，从用户体验角度来看，200毫秒被认为是第一个分界点，用户感觉不到延迟，1秒是第二个分界点，用户能感受到延迟，但是可以接受。

因此，对于一个健康的高并发系统，TP99应该控制在200毫秒以内，TP999或者TP9999应该控制在1秒以内。

##### **2.2.2 可用性指标**

高可用性是指系统具有较高的无故障运行能力，可用性 = 正常运行时间 / 系统总运行时间，一般使用几个9来描述系统的可用性。

![img](https://pica.zhimg.com/80/v2-01d222b6997c14d127107ef8e5b0281a_720w.jpg?source=1940ef5c)

对于高并发系统来说，最基本的要求是：保证3个9或者4个9。原因很简单，如果你只能做到2个9，意味着有1%的故障时间，像一些大公司每年动辄千亿以上的GMV或者收入，1%就是10亿级别的业务影响。

##### **2.2.3 可扩展性指标**

面对突发流量，不可能临时改造架构，最快的方式就是增加机器来线性提高系统的处理能力。

对于业务集群或者基础组件来说，扩展性 = 性能提升比例 / 机器增加比例，理想的扩展能力是：资源增加几倍，性能提升几倍。通常来说，扩展能力要维持在70%以上。

但是从高并发系统的整体架构角度来看，扩展的目标不仅仅是把服务设计成无状态就行了，因为当流量增加10倍，业务服务可以快速扩容10倍，但是数据库可能就成为了新的瓶颈。

像MySQL这种有状态的存储服务通常是扩展的技术难点，如果架构上没提前做好规划（垂直和水平拆分），就会涉及到大量数据的迁移。

因此，高扩展性需要考虑：服务集群、数据库、缓存和消息队列等中间件、负载均衡、带宽、依赖的第三方等，当并发达到某一个量级后，上述每个因素都可能成为扩展的瓶颈点。

### **03 高并发的实践方案有哪些？**

了解了高并发设计的3大目标后，再系统性总结下高并发的设计方案，会从以下两部分展开：先总结下通用的设计方法，然后再围绕高性能、高可用、高扩展分别给出具体的实践方案。

#### **3.1 通用的设计方法**

通用的设计方法主要是从「纵向」和「横向」两个维度出发，俗称高并发处理的两板斧：纵向扩展和横向扩展。

##### **3.1.1 纵向扩展（scale-up）**

它的目标是提升单机的处理能力，方案又包括：

1、提升单机的硬件性能：通过增加内存、 CPU核数、存储容量、或者将磁盘 升级成SSD 等堆硬 件 的 方 式 来 提升 。

2、提升单机的软件性能：使用缓存减少IO次数，使用并发或者异步的方式增加吞吐量。

##### 3.1.2 横向扩展（scale-out）

因为单机性能总会存在极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力，又包括以下2个方向：

1、做好分层架构：这是横向扩展的前提，因为高并发系统往往业务复杂，通过分层处理可以简化复杂问题，更容易做到横向扩展。

![img](https://pic3.zhimg.com/80/v2-7fc0823ef36a0b46aaf7465453d2f462_720w.jpg?source=1940ef5c)

上面这种图是互联网最常见的分层架构，当然真实的高并发系统架构会在此基础上进一步完善。比如会做动静分离并引入CDN，反向代理层可以是LVS+Nginx，Web层可以是统一的API网关，业务服务层可进一步按垂直业务做微服务化，存储层可以是各种异构数据库。

2、各层进行水平扩展：无状态水平扩容，有状态做分片路由。业务集群通常能设计成无状态的，而数据库和缓存往往是有状态的，因此需要设计分区键做好存储分片，当然也可以通过主从同步、读写分离的方案提升读性能。

#### **3.2 具体的实践方案**

下面再结合我的个人经验，针对高性能、高可用、高扩展3个方面，总结下可落地的实践方案。

##### **3.2.1 高性能的实践方案**

1、集群部署，通过负载均衡减轻单机压力。

2、多级缓存，包括静态数据使用CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点key、缓存穿透、缓存并发、数据一致性等问题的处理。

3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。

4、考虑NoSQL数据库的使用，比如HBase、TiDB等，但是团队必须熟悉这些组件，且有较强的运维能力。

5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。

6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx接入层的限流、服务端的限流。

7、对流量进行 削峰填谷 ，通过 MQ承接流量。

8、并发处理，通过多线程将串行逻辑并行化。

9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。

10、 缓存预热 ，通过异步 任务 提前 预热数据到本地缓存或者分布式缓存中。

11、减少IO次数，比如数据库和缓存的批量读写、RPC的批量接口支持、或者通过冗余数据的方式干掉RPC调用。

12、减少IO时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存key的大小、压缩缓存value等。

13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For循环的计算逻辑优化，或者采用更高效的算法。

14、各种池化技术的使用和池大小的设置，包括HTTP请求池、线程池（考虑CPU密集型还是IO密集型设置核心参数）、数据库和Redis连接池等。

15、JVM优化，包括新生代和老年代的大小、GC算法的选择等，尽可能减少GC频率和耗时。

16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。

上述方案无外乎从计算和 IO 两个维度考虑所有可能的优化点，需要有配套的监控系统实时了解当前的性能表现，并支撑你进行性能瓶颈分析，然后再遵循二八原则，抓主要矛盾进行优化。

##### **3.2.2 高可用的实践方案**

1、对等节点的故障转移，Nginx和服务治理框架均支持一个节点失败后访问另一个节点。

2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如redis的哨兵模式或者集群模式、MySQL的主从切换等）。

3、接口层面的超时设置、重试策略和幂等设计。

4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。

5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。

6、MQ场景的消息可靠性保证，包括producer端的重试机制、broker侧的持久化、consumer端的ack机制等。

7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。

8、监控报警：全方位的监控体系，包括最基础的CPU、内存、磁盘、网络的监控，以及Web服务器、JVM、数据库、各类中间件的监控和业务指标的监控。

9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。

高可用的方案主要从冗余、取舍、系统运维3个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。

##### **3.2.3 高扩展的实践方案**

1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。

2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。

3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求源拆（比如To C和To B，APP和H5 ）。

### 04 经验而谈

**在短短几十分钟内，应该按照什么思路去组织内容，最终让面试官眼前一亮？**

下面我分 3 种情况，分别说下自己的意见，供大家参考。

**情况1：应届生仅仅学过 JUC 和 GC，一点宏观概念也没有，怎么回答比较好？**

说实话，大部分公司在面试应届生时，其实很少问高并发，至少我经历过的大小公司都这样。

为什么不问？因为高并发是一个很复杂的系统性问题，很注重业务场景以及实战经验。而应届生最缺的就是项目经验，所以很难区分出大家的水平。

但如果真问到了高并发，而自己仅学过 JUC，懂点 GC，该如何应对呢？给几点建议：

1、概念性的东西要掌握扎实，不少同学容易把「并发、并行、高并发」这几个概念弄混淆，认为高并发就是「高+并发」，建议大家多查查资料，了解清楚高并发一些常识性的知识。

2、打动面试官的一定是你的强项：高并发问题通常涉及到全链路，你能从架构层面去谈，也能程序语言的并发特性上去谈，还能从网络、操作系统层面去谈，角度非常多。

你完全可以引导面试官到你擅长的方向上：比如 JUC、高效算法或者数据结构、数据库索引、IO复用或者零拷贝等等，这些往往是应届生的强项。

3、相反，如果你花很多时间去大谈架构设计、中间件使用这些未实践过的技巧上，反而容易给自己挖坑。

**情况2：平时做的项目就几十 QPS，该如何应对呢？**

很多同学应该属于这种情况，做过不少项目，唯独缺少高并发的实战经验。我建议从下面几个方向去做针对性准备：

1、高并发有关的理论知识需要先有系统性的了解，然后再回到自己熟悉的业务上去思考：如果并发再提高 10 倍或者 100 倍，哪些环节会遇到问题，然后你会怎么去应对？有实际场景，并且你又能给出方案选型的合理依据，效果远比空谈理论要好很多。

2、对于项目中常用的各种中间件，比如缓存、消息队列、ElasticSearch 等，其实都是非常典型的高并发系统，你可以对某个中间件进行深入研究，然后面试时主动引导面试官到这种基础组件上，谈谈你的认识。

3、如果你对自己的高并发设计能力很有信心，也可以让面试官给你拟定一个业务场景，然后给出你的设计方案。

总之，为了弥补实战经验上的短板，理论知识一定扎实，不能浮于表面，生搬硬套，不然很容易留下负面印象。

**情况3：很多高并发技巧都有遇到或者实操过，怎么才能形成比较系统的回答？**

这种情况属于有高并发经验，但是平时思考偏少，又没意识去做系统性整理，面试时很容易发挥失常。

建议可以参考我的回答：分别从高性能、高可用、高扩展这 3 个大方向做一次盘点，先找出技术亮点。

每个亮点，一定要扎进细节里去做整理和深度思考，弄清楚 Why 和 How：为什么要用这个技巧？它是怎么发挥作用的？会引发哪些关联问题？最终取得了什么效果？此外，业务背景以及指标性的数据都要做到心中有数。

找到亮点后，可以尝试找一条主脉络：比如按时间顺序、或者系统演进的顺序进行串联，这样比较符合高并发设计的基本原则，会让你的方案更接地气。

## 2 民工哥

### **2.1 什么是高并发？**

狭义来讲就是你的网站/软件同一时间能承受的用户数量有多少

**相关指标有**

**[并发数)：**对网站/软件同时发起的请求数，一般也可代表实际的用户

**每秒响应时间：**常指一次请求到系统正确响的时间（以秒为单位）

**TPS（每秒事务数）：**每秒钟可以处理的事务（请求响应），大概的计算公式为：并发数/每秒响应时间=TPS

**QPS（每秒查询数）：**TPS事务有读有写，而QPS指的是读取，一般情况QPS应是高于TPS的

**IP（独立IP）：**一个IP可以发生多次UV和PV

**PV（访问量）：**即Page View，页面浏览或点周量，用户每次新刷新即被计算一次

**UV（独立访客）：**一般通过cookies记录等判断为一个独立用户，同一IP可能有多个UV（共享IP），发生多次PV

**流量（网络流量）：**请求所产生的网络流量，因为受限于带宽也是并发中的一个重要指标。

[什么是高并发架构？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI0MDQ4MTM5NQ%3D%3D%26mid%3D2247490599%26idx%3D2%26sn%3Db0fccf0e771e69ded533ec645f07cd50%26chksm%3De91b793bde6cf02dff4b3f9705cc265747d351d1394ebdf2072302f112994542711a6e6f737f%26token%3D957072017%26lang%3Dzh_CN%23rd)

了解这些之后，你可以再看看一些大厂的架构演进：[千万级规模高性能、高并发的网络架构经验分享](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI0MDQ4MTM5NQ%3D%3D%26mid%3D2247485817%26idx%3D1%26sn%3Da9c77972ac54e31c105d349fc5fc8837%26chksm%3De91b6c65de6ce5736d8093490bc7d8e6079585af1bfea4a16f1ca6fd3cd007d2607bfd2bfe83%26token%3D957072017%26lang%3Dzh_CN%23rd) 这样，你至少知道了，在这些技术架构演进的过程需要用到哪些技术，有哪些解决方案。

一般的面试题问到这些，无非就是考查你的基础知识水平，然后再看你的应对方法：[如何应对大流量、高并发？？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI0MDQ4MTM5NQ%3D%3D%26mid%3D2247486327%26idx%3D2%26sn%3D48dd58f898de9768cca8c691afb63ca9%26chksm%3De91b6e6bde6ce77d53c104bb31f443be6e677dd331312ce91cc67f867f73a1e7137000d5d16b%26token%3D957072017%26lang%3Dzh_CN%23rd) ，[高并发下怎么优化能避免服务器压力过大？](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI0MDQ4MTM5NQ%3D%3D%26mid%3D2247486577%26idx%3D1%26sn%3D6690cc249eea82cb08fe1d23ba3e2552%26chksm%3De91b696dde6ce07b032244666544656e7b9f87bbe7fa4a757a82f0407fdd998d355805e3958e%26token%3D957072017%26lang%3Dzh_CN%23rd)

![img](https://pica.zhimg.com/80/v2-6cf3eae5b3b04ec695148c08cf0968e8_720w.jpg?source=1940ef5c)

下面是一些常用的解决方案

**1、系统集群化部署+负载均衡**

（1）添加负载均衡层，将请求均匀打到系统层。

（2）系统层采用集群化多活部署，扛住初步的并发压力。

**2、数据库分库分表+读写分离+分布式数据库**

（1）**分库分表**：水平拆分、垂直拆分（弊端太多如关联查询）。

（2）读写分离：主库写，从库读（数据同步延迟）。

（3）分布式数据库：TiDB（HTAP、兼容MySQ协议、水平扩展、分布式事务）

**3、缓存**

（1）本地缓存：本地磁盘或内存。

（2）分布式缓存：用缓存集群抗住大量的读请求。

（3）预缓存，多级缓存。

**4、消息中间件**

（1）系统解耦，数据同步。

（2）请求异步化处理，实现削峰填谷的效果。

**5、应用拆分（微服务）**

（1）按业务拆分、减少耦合。

（2）分级部署，扩容缩容。

（3）应用资源隔离。

**6、CDN（内容分发网络）**

（1）尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节, 使内容传输的更快更稳定。

（2）CDN能够实时地根据网络流量和各节点的链接，负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。