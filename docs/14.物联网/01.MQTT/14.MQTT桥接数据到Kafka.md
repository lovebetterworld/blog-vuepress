---
title: MQTT桥接数据到Kafka
date: 2022-05-09 16:21:25
permalink: /pages/28e05a/
categories:
  - 物联网
  - MQTT
tags:
  - 
---
## 1 解决方案及思路

> 参考文章：[【大物联网技术干货】如何将物联网数据从设备连接到Kafka集群？_牵牛刘先生的博客-CSDN博客_kafka物联网](https://blog.csdn.net/liuchunhang/article/details/114729621?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-2-114729621-blog-107274727.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~default-2-114729621-blog-107274727.pc_relevant_default&utm_relevant_index=5)

有四种不同的架构方法来实现这种类型的桥梁：

### 1.1 Kafka连接（Kafka Connect）MQTT

Kafka有一个扩展框架，叫做Kafka Connect，它允许Kafka从其他系统摄取数据。Kafka Connect for MQTT充当一个MQTT客户端，订阅来自MQTT代理的所有消息。

如果您没有对MQTT代理的控制权，那么Kafka Connect for MQTT是一个值得追求的方法。这种方法允许Kafka摄取MQTT消息流。

在MQTT中使用Kafka Connect存在性能和可伸缩性限制。如前所述，Kafka Connect for MQTT是一个MQTT客户机，它订阅通过代理传递的所有MQTT消息。MQTT客户机库并不打算处理大量的MQTT消息，因此使用这种方法的物联网系统将存在性能和可伸缩性问题。

这种方法集中了业务和消息转换逻辑，并创建了紧密耦合，这在[分布式](https://so.csdn.net/so/search?q=分布式&spm=1001.2101.3001.7020)（微服务）体系结构中应该避免。业界领先的咨询公司Thoughtworks称这是一种反模式，甚至在他们之前的技术雷达出版物中将Kafka归入“持有”类别。

### 1.2 MQTT代理

如何将物联网数据从设备连接到Kafka集群？

另一种方法是使用代理应用程序，它接受来自物联网设备的MQTT消息，但不实现发布/订阅或任何MQTT会话特性，因此不是MQTT代理。物联网设备连接到MQTT代理，然后该代理将MQTT消息推送到Kafka代理。

MQTT代理方法允许在Kafka部署中完成MQTT消息处理，因此可以从单个控制台完成管理和操作。MQTT代理通常是无状态的，因此通过添加代理的多个实例，它（理论上）可以独立于Kafka集群进行伸缩。

MQTT代理的限制是它不是真正的MQTT实现。MQTT代理不是基于发布/订阅的。相反，它在设备和Kafka之间创建了一个紧密耦合的流。MQTT发布/订阅的好处是，它创建了一个松散耦合的端点系统（设备或后端应用程序），可以在每个端点之间通信和移动数据。例如，MQTT允许两个设备之间的通信，例如两个连接的汽车可以彼此通信，但是MQTT代理应用程序只允许从一辆汽车到Kafka集群的数据传输，而不允许与另一辆汽车的数据传输。

一些Kafka MQTT代理应用程序支持QoS级别等特性。值得注意的是，只有在MQTT客户端重新连接到相同的MQTT代理实例时，才可能在连接丢失后恢复QoS消息流，而这是不可能的，前提是使用负载均衡器，该均衡器使用最少连接或循环策略来实现可伸缩性。因此，在MQTT中使用QoS级别的主要原因（即没有消息丢失）仅适用于稳定连接，这在大多数物联网场景中是一个不现实的假设。

使用这种方法的主要风险是代理不是功能完整的MQTT代理，因此它不是MQTT规范定义的MQTT实现，只是实现了一个很小的子集，因此它不是一个标准化的解决方案。为了在MQTT客户机中正确地使用MQTT，需要一个功能齐全的MQTT代理。

如果消息丢失不是一个重要因素，并且没有使用为可靠的物联网通信而设计的MQTT特性，如果您只想通过Internet单向地向Kafka发送数据，那么代理方法可能是一个轻量级的替代方法。

### 1.3 构建您自己的自定义桥接

一些公司建立了他们自己的MQTT到Kafka桥。典型的方法是使用开源MQTT客户端库和开源Kafka客户端库创建应用程序。自定义应用程序负责在MQTT代理和Kafka实例之间调换和路由数据。

这种方法的主要挑战是，自定义应用程序通常没有设计成容错和弹性。如果物联网解决方案要求和端到端保证至少一次或确切一次消息传递，这就变得很重要。例如，设置为服务质量级别1或2的MQTT消息发送到自定义应用程序将确认收到消息。但是，如果自定义应用程序在将消息转发给Kafka之前崩溃，则消息将丢失。类似地，如果Kafka集群不可用，自定义应用程序将需要缓冲MQTT消息。如果定制应用程序在Kafka集群恢复可用之前崩溃，所有缓冲的消息将丢失。要解决这些问题，定制应用程序将需要大量的开发工作，构建与Kafka和MQTT代理中已经发现的技术类似的功能。

### 1.4 MQTT代理扩展

最后一种方法是扩展MQTT代理，以创建包含本机Kafka协议的扩展。这允许MQTT代理充当一流的Kafka客户机，并将物联网设备数据流传递给多个Kafka集群。

要实现这种方法，您需要访问MQTT代理，代理需要能够安装扩展。

这种方法允许物联网解决方案使用本地MQTT实现和本地Kafka实现。物联网设备使用MQTT客户机将数据发送到功能齐全的MQTT代理。MQTT代理被扩展为包括一个本地Kafka客户机，并将MQTT消息置换到Kafka协议。这使得物联网数据可以同时路由到多个Kafka集群和非Kafka应用程序。使用MQTT代理还将提供对物联网设备所需的所有MQTT特性的访问，例如遗嘱和遗嘱。MQTT代理（如HiveMQ）是为高可用性、持久性、性能和弹性而设计的，因此消息可以在Kafka不可写时在代理上缓冲，因此重要消息不会从物联网设备中丢失。因此，这种方法提供了真正的端到端消息传递保证，即使是在不可靠的网络、公共Internet通信和不断变化的网络拓扑（在容器化部署中经常看到，例如Kubernetes）。

## 2 EMQ与Kafka插件emqx_plugin_kafka修改使用

> 参考资料：[EMQ与Kafka插件emqx_plugin_kafka修改使用_TuYue丶的博客-CSDN博客_kafka mqtt插件](https://blog.csdn.net/qq_43801592/article/details/123794539?spm=1001.2101.3001.6650.17&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-17-123794539-blog-107274727.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-17-123794539-blog-107274727.pc_relevant_default&utm_relevant_index=20)

插件地址：https://[github](https://so.csdn.net/so/search?q=github&spm=1001.2101.3001.7020).com/ULTRAKID/emqx_plugin_kafka

### 2.1 拉取插件代码导入自己仓库

拉取插件代码

```shell
git clone https://github.com/ULTRAKID/emqx_plugin_kafka.git
```

之后通过git传入自己仓库或者直接fork一份到自己github仓库

### 2.2 EMQX编译

拉取EMQX[源码](https://so.csdn.net/so/search?q=源码&spm=1001.2101.3001.7020)（先配置ssh免密）

```shell
git clone git@github.com:emqx/emqx.git
```

修改EMQX主目录下Makefile文件，添加如下行

```shell
export EMQX_EXTRA_PLUGINS = emqx_plugin_kafka
```

修改EMQX目录下lib-extra/plugins文件，在erlang_plugins中添加如下行打入emqx_plugin_kafka插件

```shell
, {emqx_plugin_kafka, {git, "git@git.talkweb.com.cn:iot3.0/cloud/iot/emqx_plugin_kafka.git", {branch, "main"}}} #这里仓库为自己仓库地址 方便之后代码修改提交
```

编译

```shell
make
```

此过程可能会有点长 甚至有些依赖包下不下来 无法访问github

这是由于访问github网速慢的原因 推荐SwitchHosts这个软件来替换Hosts文件加快访问github

具体操作见链接：https://zhuanlan.zhihu.com/p/443847295

### 2.3 运行

配置kafka地址，修改emqx配置文件emqx_plugin_kafka.conf，具体目录在_build/emqx/rel/emqx/etc/plugins

**注意：_bulid目录需要在编译后才会生成**

```shell
vim _build/emqx/rel/emqx/etc/plugins/emqx_plugin_kafka.conf 

kafka.host = 192.168.141.77 #这里修改为自己kafka所在服务器的ip

kafka.port = 9092 
```

开启emqx日志级别为info 方便之后日志查看

```shell
vim _build/emqx/rel/emqx/etc/emqx.conf

log.level = info
```

运行emqx

```shell
_build/emqx/rel/emqx/bin/emqx console
```

此时应该没什么问题

访问emqx启动服务器ip:18083，找到插件（plugins）菜单，找到插件emqx_plugin_kafka选择启动

![在这里插入图片描述](https://img-blog.csdnimg.cn/db4902095b6f48a0b91c9680c8cdbf78.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAVHVZdWXkuLY=,size_20,color_FFFFFF,t_70,g_se,x_16)

通过MQTTX工具连接emqx，ip选择emqx安装所在服务器ip，名字随便起，就可以连接

![img](https://img-blog.csdnimg.cn/76f3b6aadb06425d9fd4ab3a011f376a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAVHVZdWXkuLY=,size_20,color_FFFFFF,t_70,g_se,x_16)

连接成功后就可以往emqx指定topic发送消息

### 2.4 Kafka工具

这里我们选择KafkaTools，连接到Kafka服务器所在ip的Kafka之后，因为我们还没有修改插件中Kafka默认topic，我们在topic – emqx-topic就会收到上述消息

![在这里插入图片描述](https://img-blog.csdnimg.cn/3cec110fde594ff7b99f5a9077ebd04d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAVHVZdWXkuLY=,size_20,color_FFFFFF,t_70,g_se,x_16)

同时emqx所在服务器也会打印info信息

### 2.5 插件代码修改

**注意：此部分只是按照个人需求修改**

修改配置文件emqx_plugin_kafka.conf

```shell
kafka.host = 192.168.141.77 #kafka的服务器地址 这里配置就不用每次重新编译emqx时去改kafka的配置文件的host
kafka.payloadtopic = tlink_device_ #kafka的topic前缀
```

修改rebar.config.script变量GitDescribe为master

```erlang
EMQX_MGMT_DEP = {emqx_management, {git, UrlPrefix ++ "emqx-management", "master"}},
```

修改主要逻辑代码emqx_plugin_kafka.erl

添加按mqtt的topic分发消息到kafka不同的topic

```erlang
get_kafka_topic_produce(Topic, Message) ->
  ?LOG_INFO("[KAFKA PLUGIN]Kafka topic = -s-n", [Topic]),
  TopicPrefix = string:left(binary_to_list(Topic),6),
  TlinkFlag = string:equal(TopicPrefix, <<"tlink/">>),
  if
    TlinkFlag == true ->
      TopicStr = binary_to_list(Topic),
      OtaIndex = string:str(TopicStr,"ota"),
      SubRegisterIndex = string:str(TopicStr,"sub/register"),
      SubLogin = string:str(TopicStr,"sub/login"),
      if
        OtaIndex /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"ota">>]);
        SubRegisterIndex /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"sub_register">>]);
        SubLogin /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"sub_status">>]);
        OtaIndex + SubRegisterIndex + SubLogin == 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"msg">>])
      end,
      produce_kafka_payload(TopicKafka, Topic, Message);
    TlinkFlag == false ->
      ?LOG_INFO("[KAFKA PLUGIN]MQTT topic prefix is not tlink = ~s~n",[Topic])
  end,
  ok.
```

完整代码如下

```erlang
%%--------------------------------------------------------------------
%% Copyright (c) 2015-2017 Feng Lee <feng@emqtt.io>.
%%
%% Modified by Ramez Hanna <rhanna@iotblue.net>
%% 
%% Licensed under the Apache License, Version 2.0 (the "License");
%% you may not use this file except in compliance with the License.
%% You may obtain a copy of the License at
%%
%%     http://www.apache.org/licenses/LICENSE-2.0
%%
%% Unless required by applicable law or agreed to in writing, software
%% distributed under the License is distributed on an "AS IS" BASIS,
%% WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
%% See the License for the specific language governing permissions and
%% limitations under the License.
%%--------------------------------------------------------------------

-module(emqx_plugin_kafka).

% -include("emqx_plugin_kafka.hrl").

% -include_lib("emqx/include/emqx.hrl").

-include("emqx.hrl").
-include_lib("kernel/include/logger.hrl").

-export([load/1, unload/0]).

%% Client Lifecircle Hooks
-export([on_client_connect/3
  , on_client_connack/4
  , on_client_connected/3
  , on_client_disconnected/4
  , on_client_authenticate/3
  , on_client_check_acl/5
  , on_client_subscribe/4
  , on_client_unsubscribe/4
]).

%% Session Lifecircle Hooks
-export([on_session_created/3
  , on_session_subscribed/4
  , on_session_unsubscribed/4
  , on_session_resumed/3
  , on_session_discarded/3
  , on_session_takeovered/3
  , on_session_terminated/4
]).

%% Message Pubsub Hooks
-export([on_message_publish/2
  , on_message_delivered/3
  , on_message_acked/3
  , on_message_dropped/4
]).


%% Called when the plugin application start
load(Env) ->
  ekaf_init([Env]),
  emqx:hook('client.connect', {?MODULE, on_client_connect, [Env]}),
  emqx:hook('client.connack', {?MODULE, on_client_connack, [Env]}),
  emqx:hook('client.connected', {?MODULE, on_client_connected, [Env]}),
  emqx:hook('client.disconnected', {?MODULE, on_client_disconnected, [Env]}),
  emqx:hook('client.authenticate', {?MODULE, on_client_authenticate, [Env]}),
  emqx:hook('client.check_acl', {?MODULE, on_client_check_acl, [Env]}),
  emqx:hook('client.subscribe', {?MODULE, on_client_subscribe, [Env]}),
  emqx:hook('client.unsubscribe', {?MODULE, on_client_unsubscribe, [Env]}),
  emqx:hook('session.created', {?MODULE, on_session_created, [Env]}),
  emqx:hook('session.subscribed', {?MODULE, on_session_subscribed, [Env]}),
  emqx:hook('session.unsubscribed', {?MODULE, on_session_unsubscribed, [Env]}),
  emqx:hook('session.resumed', {?MODULE, on_session_resumed, [Env]}),
  emqx:hook('session.discarded', {?MODULE, on_session_discarded, [Env]}),
  emqx:hook('session.takeovered', {?MODULE, on_session_takeovered, [Env]}),
  emqx:hook('session.terminated', {?MODULE, on_session_terminated, [Env]}),
  emqx:hook('message.publish', {?MODULE, on_message_publish, [Env]}),
  emqx:hook('message.delivered', {?MODULE, on_message_delivered, [Env]}),
  emqx:hook('message.acked', {?MODULE, on_message_acked, [Env]}),
  emqx:hook('message.dropped', {?MODULE, on_message_dropped, [Env]}).

on_client_connect(ConnInfo = #{clientid := ClientId}, Props, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) connect, ConnInfo: ~p, Props: ~p~n",
    [ClientId, ConnInfo, Props]),
  ok.

on_client_connack(ConnInfo = #{clientid := ClientId}, Rc, Props, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) connack, ConnInfo: ~p, Rc: ~p, Props: ~p~n",
    [ClientId, ConnInfo, Rc, Props]),
  ok.

on_client_connected(ClientInfo = #{clientid := ClientId}, ConnInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) connected, ClientInfo:~n~p~n, ConnInfo:~n~p~n",
    [ClientId, ClientInfo, ConnInfo]),
  {IpAddr, _Port} = maps:get(peername, ConnInfo),
  Action = <<"connected">>,
  Now = now_mill_secs(os:timestamp()),
  Online = 1,
  Payload = [
    {action, Action},
    {clientid, ClientId},
    {username, maps:get(username, ClientInfo)},
    {keepalive, maps:get(keepalive, ConnInfo)},
    {ipaddress, iolist_to_binary(ntoa(IpAddr))},
    {proto_name, maps:get(proto_name, ConnInfo)},
    {proto_ver, maps:get(proto_ver, ConnInfo)},
    {timestamp, Now},
    {online, Online}
  ],
  Topic = list_to_binary([ekaf_get_topic(), <<"status">>]),
  {ok, MessageBody} = emqx_json:safe_encode(Payload),
  produce_kafka_payload(Topic, Action, MessageBody),
  ok.

on_client_disconnected(ClientInfo = #{clientid := ClientId}, ReasonCode, ConnInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) disconnected due to ~p, ClientInfo:~n~p~n, ConnInfo:~n~p~n",
    [ClientId, ReasonCode, ClientInfo, ConnInfo]),
  Action = <<"disconnected">>,
  Now = now_mill_secs(os:timestamp()),
  Online = 0,
  Payload = [
    {action, Action},
    {clientid, ClientId},
    {username, maps:get(username, ClientInfo)},
    {reason, ReasonCode},
    {timestamp, Now},
    {online, Online}
  ],
  Topic = list_to_binary([ekaf_get_topic(), <<"status">>]),
  {ok, MessageBody} = emqx_json:safe_encode(Payload),
  produce_kafka_payload(Topic, Action, MessageBody),
  ok.

on_client_authenticate(_ClientInfo = #{clientid := ClientId}, Result, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) authenticate, Result:~n~p~n", [ClientId, Result]),
  ok.

on_client_check_acl(_ClientInfo = #{clientid := ClientId}, Topic, PubSub, Result, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) check_acl, PubSub:~p, Topic:~p, Result:~p~n",
    [ClientId, PubSub, Topic, Result]),
  ok.

%%---------------------------client subscribe start--------------------------%%
on_client_subscribe(#{clientid := ClientId}, _Properties, TopicFilters, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) will subscribe: ~p~n", [ClientId, TopicFilters]),
  ok.
%%---------------------client subscribe stop----------------------%%
on_client_unsubscribe(#{clientid := ClientId}, _Properties, TopicFilters, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Client(~s) will unsubscribe ~p~n", [ClientId, TopicFilters]),
  ok.

on_message_dropped(#message{topic = <<"$SYS/", _/binary>>}, _By, _Reason, _Env) ->
  ok;
on_message_dropped(Message, _By = #{node := Node}, Reason, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Message dropped by node ~s due to ~s: ~s~n",
    [Node, Reason, emqx_message:format(Message)]),
  ok.


%%---------------------------message publish start--------------------------%%
on_message_publish(Message = #message{topic = <<"$SYS/", _/binary>>}, _Env) ->
  ok;
on_message_publish(Message, _Env) ->
  %%?LOG_INFO("[KAFKA PLUGIN]Client publish before produce, Message:~n~p~n",[Message]),
  %%{ok, Payload} = format_payload(Message),
  %%get_kafka_topic_produce(Message#message.topic, Payload),
  %% produce_kafka_payload(<<"publish">>, Message#message.topic, Payload),
  %%?LOG_INFO("[KAFKA PLUGIN]Client publish after produce, Payload:~n~p~n, Topic:~n~p~n",[Payload, Message#message.topic]),
  ok.
%%---------------------message publish stop----------------------%%

on_message_delivered(_ClientInfo = #{clientid := ClientId}, Message, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Message delivered to client(~s): ~s~n",
    [ClientId, emqx_message:format(Message)]),
  Topic = Message#message.topic,
  Payload = Message#message.payload,
  get_kafka_topic_produce(Topic, Payload),
  ok.

on_message_acked(_ClientInfo = #{clientid := ClientId}, Message, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Message acked by client(~s): ~s~n",
    [ClientId, emqx_message:format(Message)]),
  Topic = Message#message.topic,
  Payload = Message#message.payload,
  get_kafka_topic_produce(Topic, Payload),
  ok.

%%--------------------------------------------------------------------
%% Session Lifecircle Hooks
%%--------------------------------------------------------------------

on_session_created(#{clientid := ClientId}, SessInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) created, Session Info:~n~p~n", [ClientId, SessInfo]),
  ok.


on_session_subscribed(#{clientid := ClientId}, Topic, SubOpts, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) subscribed ~s with subopts: ~p~n", [ClientId, Topic, SubOpts]),
  ok.

on_session_unsubscribed(#{clientid := ClientId}, Topic, Opts, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) unsubscribed ~s with opts: ~p~n", [ClientId, Topic, Opts]),
  ok.

on_session_resumed(#{clientid := ClientId}, SessInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) resumed, Session Info:~n~p~n", [ClientId, SessInfo]),
  ok.

on_session_discarded(_ClientInfo = #{clientid := ClientId}, SessInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) is discarded. Session Info: ~p~n", [ClientId, SessInfo]),
  ok.

on_session_takeovered(_ClientInfo = #{clientid := ClientId}, SessInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) is takeovered. Session Info: ~p~n", [ClientId, SessInfo]),
  ok.

on_session_terminated(_ClientInfo = #{clientid := ClientId}, Reason, SessInfo, _Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Session(~s) is terminated due to ~p~nSession Info: ~p~n",
    [ClientId, Reason, SessInfo]),
  ok.

ekaf_init(_Env) ->
  io:format("Init emqx plugin kafka....."),
  {ok, BrokerValues} = application:get_env(emqx_plugin_kafka, broker),
  KafkaHost = proplists:get_value(host, BrokerValues),
  ?LOG_INFO("[KAFKA PLUGIN]KafkaHost = ~s~n", [KafkaHost]),
  KafkaPort = proplists:get_value(port, BrokerValues),
  ?LOG_INFO("[KAFKA PLUGIN]KafkaPort = ~s~n", [KafkaPort]),
  KafkaPartitionStrategy = proplists:get_value(partitionstrategy, BrokerValues),
  KafkaPartitionWorkers = proplists:get_value(partitionworkers, BrokerValues),
  KafkaTopic = proplists:get_value(payloadtopic, BrokerValues),
  ?LOG_INFO("[KAFKA PLUGIN]KafkaTopic = ~s~n", [KafkaTopic]),
  application:set_env(ekaf, ekaf_bootstrap_broker, {KafkaHost, list_to_integer(KafkaPort)}),
  application:set_env(ekaf, ekaf_partition_strategy, list_to_atom(KafkaPartitionStrategy)),
  application:set_env(ekaf, ekaf_per_partition_workers, KafkaPartitionWorkers),
  application:set_env(ekaf, ekaf_bootstrap_topics, list_to_binary(KafkaTopic)),
  application:set_env(ekaf, ekaf_buffer_ttl, 10),
  application:set_env(ekaf, ekaf_max_downtime_buffer_size, 5),
  % {ok, _} = application:ensure_all_started(kafkamocker),
  {ok, _} = application:ensure_all_started(gproc),
  % {ok, _} = application:ensure_all_started(ranch),
  {ok, _} = application:ensure_all_started(ekaf).

ekaf_get_topic() ->
  {ok, Topic} = application:get_env(ekaf, ekaf_bootstrap_topics),
  Topic.


%% Called when the plugin application stop
unload() ->
  emqx:unhook('client.connect', {?MODULE, on_client_connect}),
  emqx:unhook('client.connack', {?MODULE, on_client_connack}),
  emqx:unhook('client.connected', {?MODULE, on_client_connected}),
  emqx:unhook('client.disconnected', {?MODULE, on_client_disconnected}),
  emqx:unhook('client.authenticate', {?MODULE, on_client_authenticate}),
  emqx:unhook('client.check_acl', {?MODULE, on_client_check_acl}),
  emqx:unhook('client.subscribe', {?MODULE, on_client_subscribe}),
  emqx:unhook('client.unsubscribe', {?MODULE, on_client_unsubscribe}),
  emqx:unhook('session.created', {?MODULE, on_session_created}),
  emqx:unhook('session.subscribed', {?MODULE, on_session_subscribed}),
  emqx:unhook('session.unsubscribed', {?MODULE, on_session_unsubscribed}),
  emqx:unhook('session.resumed', {?MODULE, on_session_resumed}),
  emqx:unhook('session.discarded', {?MODULE, on_session_discarded}),
  emqx:unhook('session.takeovered', {?MODULE, on_session_takeovered}),
  emqx:unhook('session.terminated', {?MODULE, on_session_terminated}),
  emqx:unhook('message.publish', {?MODULE, on_message_publish}),
  emqx:unhook('message.delivered', {?MODULE, on_message_delivered}),
  emqx:unhook('message.acked', {?MODULE, on_message_acked}),
  emqx:unhook('message.dropped', {?MODULE, on_message_dropped}).

produce_kafka_payload(Topic, Key, Payload) ->
%%  Topic = ekaf_get_topic(),

  ?LOG_INFO("[KAFKA PLUGIN]Message = ~s~n",[Payload]),
  ekaf_lib:common_async(produce_async_batched, Topic, {Key,Payload}).

get_kafka_topic_produce(Topic, Message) ->
  ?LOG_INFO("[KAFKA PLUGIN]Kafka topic = -s-n", [Topic]),
  TopicPrefix = string:left(binary_to_list(Topic),6),
  TlinkFlag = string:equal(TopicPrefix, <<"tlink/">>),
  if
    TlinkFlag == true ->
      TopicStr = binary_to_list(Topic),
      OtaIndex = string:str(TopicStr,"ota"),
      SubRegisterIndex = string:str(TopicStr,"sub/register"),
      SubLogin = string:str(TopicStr,"sub/login"),
      if
        OtaIndex /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"ota">>]);
        SubRegisterIndex /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"sub_register">>]);
        SubLogin /= 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"sub_status">>]);
        OtaIndex + SubRegisterIndex + SubLogin == 0 ->
          TopicKafka = list_to_binary([ekaf_get_topic(), <<"msg">>])
      end,
      produce_kafka_payload(TopicKafka, Topic, Message);
    TlinkFlag == false ->
      ?LOG_INFO("[KAFKA PLUGIN]MQTT topic prefix is not tlink = ~s~n",[Topic])
  end,
  ok.

consume_kafka(Topic) ->
  ?LOG_INFO("[KAFKA PLUGIN]Consuming kafka message"),
  ekaf:pick(Topic,(a,b,c) ->
    ?LOG_INFO("[KAFKA PLUGIN]Consuming kafka message a = ~s~n, b = ~s~n, c = ~s~n", a, b, c),
    Msg = emqx_message:make(ClientId, Qos, Topic, Payload),
    ?LOG_INFO("[KAFKA PLUGIN]Consuming kafka message = ~s~n", Msg),
    emqx_broker:publish(Msg).
  )


ntoa({0, 0, 0, 0, 0, 16#ffff, AB, CD}) ->
  inet_parse:ntoa({AB bsr 8, AB rem 256, CD bsr 8, CD rem 256});
ntoa(IP) ->
  inet_parse:ntoa(IP).
now_mill_secs({MegaSecs, Secs, _MicroSecs}) ->
  MegaSecs * 1000000000 + Secs * 1000 + _MicroSecs.
```

修改代码之后需要先清除再编译执行

```shell
make clean
make
```

具体见2、3步

另可能会发生修改的代码会不生效的情况，这里有两种解决办法

1、直接再emqx中修改代码，缺点是没有代码提示

2、在其它端修改代码，但是清除时需要清除所有（make clean-all） 缺点是emqx编译时需要重新下载所有依赖

我们可以采取在其他端修改代码，修改完之后将代码覆盖到emqx中

**-------------------------------------------------------------分割线-------------------------------------------------------------------------------------**

上述连接kafka转发消息用的是ekaf，为了应对需求，满足消费kafka消息转给emqx，后续是使用brod作为连接kafka并转发消息的客户端

### 2.6 主要功能描述

1、根据emqx的消息topic后缀转发到kafka的指定topic；

2、消费kafka的msg_down topic消息转发到emqx；

3、消费kafka的kick_out topic将emqx中符合要求的客户端连接踢下线；

4、消费kafka的acl_clean topic将emqx中符合要求的客户端连接acl缓存删除。

### 2.7 主要方法描述

1、brod_get_topic

用于读取配置文件中配置的kafka的topic前缀

2、getPartition

用于读取kafka指定key的partition

3、produce_kafka_message

用于将message通过brod转发到指定kafka的topic、key和partition

4、get_kafka_topic_produce

根据emqx的topic拼接kafka的topic，随后在方法中调用produce_kafka_message执行向kafka中写入消息

5、kafka_consume

kafka消费指定topic集合的消息，**init和handlemessage是它默认的回调**

6、handle_message

该方法通过判断不同的topic名字，调用其他不同的方法来实现相关功能，包括消息转发emqx、剔除客户端、删除客户端acl权限

7、handle_message_msg_down

用于将kafka中的消息转发到emqx中

8、get_username

根据消息体获取其中的数据，来查询到username

9、get_client_list_by_username

根据username获取该username下的所有client信息

10、kick_out

将指定client集合中的clientid连接踢下线

11、acl_clean

将指定client集合中的clientid的连接acl缓存删除

### 2.8 主要业务代码

```erlang
brod_get_topic() ->
  {ok, Kafka} = application:get_env(?MODULE, broker),
  Topic_prefix = proplists:get_value(payloadtopic, Kafka),
  Topic_prefix.

getPartition(Key) ->
  {ok, Kafka} = application:get_env(?MODULE, broker),
  PartitionNum = proplists:get_value(partition, Kafka),
  <<Fix:120, Match:8>> = crypto:hash(md5, Key),
  abs(Match) rem PartitionNum.
produce_kafka_message(Topic, Message, ClientId, Env) ->
  Key = iolist_to_binary(ClientId),
  Partition = getPartition(Key),
  %%JsonStr = jsx:encode(Message),
  Kafka = proplists:get_value(broker, Env),
  IsAsyncProducer = proplists:get_value(is_async_producer, Kafka),
  if
    IsAsyncProducer == false ->
      brod:produce_sync(brod_client_1, Topic, Partition, ClientId, Message);
    true ->
      brod:produce_no_ack(brod_client_1, Topic, Partition, ClientId, Message)
%%      brod:produce(brod_client_1, Topic, Partition, ClientId, JsonStr)
  end,
  ok.

get_kafka_topic_produce(Topic, Message, Env) ->
  ?LOG_INFO("[KAFKA PLUGIN]Kafka topic = -s-n", [Topic]),
  TopicPrefix = string:left(binary_to_list(Topic),6),
  TlinkFlag = string:equal(TopicPrefix, <<"tlink/">>),
  if
    TlinkFlag == true ->
      TopicStr = binary_to_list(Topic),
      OtaIndex = string:str(TopicStr,"ota"),
      SubRegisterIndex = string:str(TopicStr,"sub/register"),
      SubLogin = string:str(TopicStr,"sub/login"),
      if
        OtaIndex /= 0 ->
          TopicKafka = list_to_binary([brod_get_topic(), <<"ota">>]);
        SubRegisterIndex /= 0 ->
          TopicKafka = list_to_binary([brod_get_topic(), <<"sub_register">>]);
        SubLogin /= 0 ->
          TopicKafka = list_to_binary([brod_get_topic(), <<"sub_status">>]);
        true ->
          TopicKafka = list_to_binary([brod_get_topic(), <<"msg">>])
      end,
      produce_kafka_message(TopicKafka, Message, Topic, Env);
    TlinkFlag == false ->
      ?LOG_INFO("[KAFKA PLUGIN]MQTT topic prefix is not tlink = ~s~n",[Topic])
  end,
  ok.

kafka_consume(Topics)->
  GroupConfig = [{offset_commit_policy, commit_to_kafka_v2},
    {offset_commit_interval_seconds, 5}
  ],
  GroupId = <<"emqx_cluster">>,
  ConsumerConfig = [{begin_offset, earliest}],
  brod:start_link_group_subscriber(brod_client_1, GroupId, Topics,
    GroupConfig, ConsumerConfig,
    _CallbackModule  = ?MODULE,
    _CallbackInitArg = []).

handle_message(_Topic, Partition, Message, State) ->
  #kafka_message{ offset = Offset
    , key   = Key
    , value = Value
  } = Message,
  error_logger:info_msg("~p ~p: offset:~w key:~s value:~s\n",
    [self(), Partition, Offset, Key, Value]),
  TopicStr = binary_to_list(_Topic),
  MsgDown = string:equal(TopicStr,"tlink_device_msg_down"),
  KickOut = string:equal(TopicStr,"tlink_device_kick_out"),
  AclClean = string:equal(TopicStr,"tlink_device_acl_clean"),
  if
    MsgDown ->
      handle_message_msg_down(Key, Value);
    KickOut ->
      {ok, UserName} = get_username(Value),
      {ok, ClientList} = get_client_list_by_username(UserName),
      kick_out(ClientList);
    AclClean ->
      {ok, UserName} = get_username(Value),
      {ok, ClientList} = get_client_list_by_username(UserName),
      acl_clean(ClientList);
    true ->
      error_logger:error_msg("the kafka comsume topic is not exist\n")
  end,
  error_logger:info_msg("message:~p\n",[Message]),
  {ok, ack, State}.

handle_message_msg_down(Key, Value) ->
  Topic = Key,
  Payload = Value,
  Qos = 0,
  Msg = emqx_message:make(<<"consume">>, Qos, Topic, Payload),
  emqx_broker:safe_publish(Msg),
  ok.

get_username(Value) ->
  {ok,Term} =  emqx_json:safe_decode(Value),
  Map = maps:from_list(Term),
  %% 获取消息体中数据
  MessageUserName = maps:get(<<"username">>, Map),
  MessageProductKey = maps:get(<<"username">>, Map),
  MessageDeviceName = maps:get(<<"username">>, Map),
  %% 获取数据是否存在
  MessageUserNameLen = string:len(binary_to_list(MessageUserName)),
  MessageProductKeyLen = string:len(binary_to_list(MessageProductKey)),
  MessageDeviceNameLen = string:len(binary_to_list(MessageDeviceName)),
  %% 确定最终username
  if
    MessageUserNameLen /= 0 ->
      UserName = MessageUserName;
    MessageProductKeyLen /= 0, MessageDeviceNameLen/= 0 ->
      UserName = list_to_binary([MessageDeviceName, <<"&">>, MessageProductKey]);
    true ->
      UserName = <<"">>
  end,
  {ok, UserName}.

get_client_list_by_username(UserName) ->
  UserNameLen = string:len(binary_to_list(UserName)),
  if
    UserNameLen /= 0 ->
      UserNameMap = #{
        username => UserName
      },
      {ok, Client} = emqx_mgmt_api_clients:lookup(UserNameMap, {}),
      %% 获取客户端list
      ClientList = maps:get(data, Client);
    true ->
      ClientList = [],
      error_logger:error_msg("the kafka comsume kick out username is not exist")
  end,
  {ok, ClientList}.

kick_out(ClientList) ->
  ClientListLength = length(ClientList),
  if
    ClientListLength > 0 ->
      %% 遍历剔除clientid
      lists:foreach(fun(C) ->
        ClientId = maps:get(clientid, C),
        ClientIdMap = #{
          clientid => ClientId
        },
        emqx_mgmt_api_clients:kickout(ClientIdMap, {}) end,
        ClientList
      );
    true ->
      error_logger:error_msg("the kafka comsume kick out clientlist length is zero")
  end,
  ok.

acl_clean(ClientList) ->
  ClientListLength = length(ClientList),
  if
    ClientListLength > 0 ->
      %% 遍历剔除clientid
      lists:foreach(fun(C) ->
        ClientId = maps:get(clientid, C),
        ClientIdMap = #{
          clientid => ClientId
        },
        emqx_mgmt_api_clients:clean_acl_cache(ClientIdMap, {}) end,
        ClientList
      );
    true ->
      error_logger:error_msg("the kafka comsume acl clean clientlist length is zero")
  end,
  ok.
```

## 3 建EMQ连接Kafka的插件，实现消息由MQTT Broker传递至Kafka

> 参考链接：[11. 构建EMQ连接Kafka的插件，实现消息由MQTT Broker传递至Kafka_辰阳天宇的博客-CSDN博客_kafka mqtt插件](https://blog.csdn.net/qq_41094332/article/details/105589841?spm=1001.2101.3001.6650.18&utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-18-105589841-blog-107274727.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-18-105589841-blog-107274727.pc_relevant_default&utm_relevant_index=21)

本文提供了两种方式使EMQ桥接Kafka，一种是自己构建Kafka插件，另一种是安装企业版EMQ在里面配置桥接Kafka即可。

### 3.1 构建Kafka插件——环境准备

（1）make:

```
sudo apt-get install make
```

（2）git:

```
sudo apt-get install git
```

（3）由于需指定[Erlang](https://so.csdn.net/so/search?q=Erlang&spm=1001.2101.3001.7020) R21.2+ 版本，因此选择手动安装：

**方式一：网上下载安装包安装**
参考文档：
[Ubuntu16.0.4安装erlang21.1.1](https://blog.csdn.net/qq_32902741/article/details/90374806)

[Ubuntu16.04 安装Erlang（rabbitmq安装第一步）](https://blog.csdn.net/qq_42293496/article/details/86659110)

**方式二：编译安装**

- 环境准备

```
sudo apt-get install build-essential
sudo apt-get install libncurses5-dev
sudo apt-get install libssl-dev
sudo apt-get install m4
sudo apt-get install unixodbc unixodbc-dev
# sudo apt-get install freeglut3-dev libwxgtk3.0-dev
sudo apt-get install xsltproc 
sudo apt-get install fop 
sudo apt-get install tk8.5
```

下载erlang[源码](https://so.csdn.net/so/search?q=源码&spm=1001.2101.3001.7020)压缩包，

```
http://erlang.org/download/otp_src_21.2.tar.gz 
```

解压otp_src_21.2.tar.gz

```
tar -zxvf otp_src_21.2.tar.gz
```

创建Erlang目录

```
mkdir /home/user/erlang/otp_src_21.2
```

进入otp_src_21.2，执行configure命令并设置安装后的位置

```
./configure --prefix=/home/user/erlang/otp_src_21.2
```

拓展知识：[Linux ./configure --prefix 命令是什么意思？](https://blog.csdn.net/onmyways/article/details/50932983)

执行编译，安装

```
make && make install
```

最后检验一下是否安装正确：

```
bin/erl
```

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200419002424769.png)
退出命令：`halt().`

配置环境变量

```
sudo vim /etc/profile
export ERLANG_HOME=/home/user_1/erlang/otp_src_21.2
export PATH=$ERLANG_HOME/bin:$PATH
```

生效变量：`source /etc/prfile`

### 3.2 编译安装EMQ X

#### 3.2.1 获取源码

```
$ git clone -b v3.0.1 https://github.com/emqx/emqx-rel.git
```

注：本次选用EMQX的3.0.1版本

#### 3.2.2 设置环境变量

```
$ export EMQX_DEPS_DEFAULT_VSN=v3.0.1
```

#### 3.2.3 编译

```
$ cd emqx-rel && make
```

参考文档：
[编译安装EMQ X](https://docs.emqx.io/broker/v3/cn/install.html#id23)

[emq 源码编译过程](https://blog.csdn.net/caijiapeng0102/article/details/80817525)

[【服务器篇之EMQ源码编译】](https://blog.csdn.net/baidu_35751704/article/details/88343780)

### 3.3 构建Kafka插件

参考文档：
[【跟我一起搭建物联网平台】6、EMQX之Kafka插件编译安装](http://www.piaoyi.org/iot/635.html)

[EMQ集成Kafka插件编写过程 emq_plugin_kafka](https://blog.csdn.net/caijiapeng0102/article/details/80852933)

[EMQ扩展插件-emq_plugin_kafka](https://www.jianshu.com/p/1e3bfd383280)

[物联网架构成长之路(4)-EMQ插件创建](https://www.cnblogs.com/wunaozai/p/8120075.html)

[EMQ X Broker 连接kafka插件（一）](https://www.e-learn.cn/topic/3186218)

### 3.4 便捷方式

获取企业版EMQ桥接Kafka。